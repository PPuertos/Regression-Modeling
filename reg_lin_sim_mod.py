import pandas as pd
import plotly.express as px
import numpy as np
import scipy.stats as stats
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import math
import statsmodels.api as sm
from itertools import combinations
from io import StringIO

# The Critical Values of the Durbin Watson Test are from:
# https://support.minitab.com/en-us/minitab/help-and-how-to/statistical-modeling/regression/supporting-topics/model-assumptions/test-for-autocorrelation-by-using-the-durbin-watson-statistic/
csv_content = 'sample_size,n_terms,DL,DU\n6,2,0.61018,1.40015\n7,2,0.69955,1.35635\n7,3,0.46723,1.89636\n8,2,0.7629,1.33238\n8,3,0.55907,1.77711\n8,4,0.36744,2.28664\n9,2,0.82428,1.31988\n9,3,0.6291,1.69926\n9,4,0.45476,2.12816\n9,5,0.29571,2.5881\n10,2,0.87913,1.31971\n10,3,0.69715,1.64134\n10,4,0.52534,2.01632\n10,5,0.37602,2.41365\n10,6,0.24269,2.82165\n11,2,0.92733,1.32409\n11,3,0.75798,1.60439\n11,4,0.59477,1.92802\n11,5,0.44406,2.28327\n11,6,0.31549,2.64456\n11,7,0.20253,3.00447\n12,2,0.97076,1.33137\n12,3,0.81221,1.57935\n12,4,0.65765,1.86397\n12,5,0.51198,2.17662\n12,6,0.37956,2.50609\n12,7,0.26813,2.83196\n12,8,0.17144,3.1494\n13,2,1.00973,1.3404\n13,3,0.86124,1.56212\n13,4,0.71465,1.81593\n13,5,0.57446,2.09428\n13,6,0.44448,2.38967\n13,7,0.32775,2.69204\n13,8,0.23049,2.98506\n13,9,0.14693,3.26577\n14,2,1.04495,1.35027\n14,3,0.90544,1.55066\n14,4,0.76666,1.77882\n14,5,0.63206,2.02955\n14,6,0.50516,2.29593\n14,7,0.38897,2.57158\n14,8,0.28559,2.84769\n14,9,0.20013,3.11121\n14,10,0.12726,3.36038\n15,2,1.07697,1.36054\n15,3,0.94554,1.54318\n15,4,0.81396,1.75014\n15,5,0.68519,1.97735\n15,6,0.56197,2.21981\n15,7,0.44707,2.47148\n15,8,0.3429,2.72698\n15,9,0.2509,2.97866\n15,10,0.17531,3.21604\n15,11,0.11127,3.43819\n16,2,1.10617,1.37092\n16,3,0.98204,1.5386\n16,4,0.85718,1.72773\n16,5,0.734,1.93506\n16,6,0.61495,2.15672\n16,7,0.50223,2.38813\n16,8,0.39805,2.62409\n16,9,0.30433,2.86009\n16,10,0.22206,3.08954\n16,11,0.15479,3.30391\n16,12,0.09809,3.50287\n17,2,1.13295,1.38122\n17,3,1.01543,1.53614\n17,4,0.89675,1.71009\n17,5,0.77898,1.90047\n17,6,0.66414,2.10414\n17,7,0.55423,2.31755\n17,8,0.45107,2.5366\n17,9,0.35639,2.75688\n17,10,0.27177,2.97455\n17,11,0.19784,3.184\n17,12,0.13763,3.37817\n17,13,0.08711,3.55716\n18,2,1.15759,1.39133\n18,3,1.04607,1.53525\n18,4,0.9331,1.69614\n18,5,0.82044,1.87189\n18,6,0.70984,2.06\n18,7,0.60301,2.2575\n18,8,0.50158,2.46122\n18,9,0.40702,2.66753\n18,10,0.32076,2.87268\n18,11,0.24405,3.07345\n18,12,0.17732,3.26497\n18,13,0.12315,3.44141\n18,14,0.07786,3.60315\n19,2,1.18037,1.40118\n19,3,1.0743,1.53553\n19,4,0.96659,1.68509\n19,5,0.85876,1.84815\n19,6,0.75231,2.02262\n19,7,0.6487,2.20614\n19,8,0.54938,2.39602\n19,9,0.45571,2.58939\n19,10,0.36889,2.78312\n19,11,0.29008,2.97399\n19,12,0.22029,3.1593\n19,13,0.15979,3.33481\n19,14,0.11082,3.49566\n19,15,0.07001,3.64241\n20,2,1.20149,1.41073\n20,3,1.1004,1.53668\n20,4,0.99755,1.67634\n20,5,0.89425,1.82828\n20,6,0.79179,1.99079\n20,7,0.69146,2.16189\n20,8,0.59454,2.33937\n20,9,0.5022,2.52082\n20,10,0.41559,2.70374\n20,11,0.33571,2.88535\n20,12,0.26349,3.06292\n20,13,0.19978,3.23417\n20,14,0.14472,3.3954\n20,15,0.10024,3.5425\n20,16,0.06327,3.67619\n21,2,1.22115,1.41997\n21,3,1.12461,1.53849\n21,4,1.02624,1.66942\n21,5,0.92719,1.81157\n21,6,0.82856,1.9635\n21,7,0.73149,2.12355\n21,8,0.6371,2.28988\n21,9,0.54645,2.46051\n21,10,0.46055,2.63324\n21,11,0.38035,2.80588\n21,12,0.30669,2.976\n21,13,0.24033,3.14129\n21,14,0.18198,3.29979\n21,15,0.13166,3.44827\n21,16,0.09111,3.58322\n21,17,0.05747,3.70544\n22,2,1.23949,1.42888\n22,3,1.14713,1.54079\n22,4,1.05292,1.66398\n22,5,0.95783,1.79744\n22,6,0.86285,1.93996\n22,7,0.76898,2.09015\n22,8,0.67719,2.24646\n22,9,0.58843,2.40718\n22,10,0.50363,2.57051\n22,11,0.42363,2.73452\n22,12,0.34926,2.89726\n22,13,0.28119,3.05662\n22,14,0.22003,3.21061\n22,15,0.16642,3.35756\n22,16,0.12028,3.49463\n22,17,0.08315,3.6188\n22,18,0.05242,3.73092\n23,2,1.25665,1.43747\n23,3,1.16815,1.54346\n23,4,1.07778,1.65974\n23,5,0.98639,1.78546\n23,6,0.89488,1.91958\n23,7,0.8041,2.06093\n23,8,0.71493,2.20816\n23,9,0.62821,2.35988\n23,10,0.54478,2.51449\n23,11,0.46541,2.67038\n23,12,0.39083,2.82585\n23,13,0.32172,2.97919\n23,14,0.25866,3.12852\n23,15,0.20216,3.27216\n23,16,0.15274,3.40865\n23,17,0.11029,3.53549\n23,18,0.07619,3.65007\n23,19,0.04801,3.75327\n24,2,1.27276,1.44575\n24,3,1.18781,1.54639\n24,4,1.101,1.65649\n24,5,1.01309,1.77526\n24,6,0.92486,1.90184\n24,7,0.83706,2.03522\n24,8,0.75048,2.17427\n24,9,0.66589,2.31774\n24,10,0.584,2.46431\n24,11,0.50554,2.6126\n24,12,0.43119,2.76111\n24,13,0.36156,2.90835\n24,14,0.29723,3.05282\n24,15,0.23869,3.19285\n24,16,0.18635,3.327\n24,17,0.14066,3.45402\n24,18,0.1015,3.57167\n24,19,0.07006,3.67769\n24,20,0.04413,3.77297\n25,2,1.28791,1.45371\n25,3,1.20625,1.54954\n25,4,1.12276,1.65403\n25,5,1.03811,1.76655\n25,6,0.95297,1.88634\n25,7,0.86803,2.01252\n25,8,0.784,2.14412\n25,9,0.70154,2.28007\n25,10,0.62133,2.41924\n25,11,0.54401,2.56041\n25,12,0.47019,2.70229\n25,13,0.40046,2.8436\n25,14,0.33536,2.983\n25,15,0.27536,3.11913\n25,16,0.2209,3.25058\n25,17,0.17231,3.37604\n25,18,0.12995,3.49447\n25,19,0.09371,3.60384\n25,20,0.06465,3.7022\n25,21,0.0407,3.79041\n26,2,1.30219,1.46139\n26,3,1.22358,1.55281\n26,4,1.14319,1.65225\n26,5,1.06158,1.75911\n26,6,0.97937,1.87274\n26,7,0.89717,1.9924\n26,8,0.81561,2.11722\n26,9,0.73529,2.24629\n26,10,0.65683,2.37862\n26,11,0.58079,2.51315\n26,12,0.50775,2.64877\n26,13,0.43825,2.78436\n26,14,0.37279,2.91872\n26,15,0.31182,3.05067\n26,16,0.25578,3.17904\n26,17,0.20499,3.30253\n26,18,0.15977,3.42006\n26,19,0.12041,3.53067\n26,20,0.08677,3.63257\n26,21,0.05983,3.72404\n27,2,1.31568,1.46878\n27,3,1.23991,1.5562\n27,4,1.16239,1.65101\n27,5,1.08364,1.75274\n27,6,1.00421,1.86079\n27,7,0.92463,1.97449\n27,8,0.84546,2.09313\n27,9,0.76726,2.21588\n27,10,0.69057,2.3419\n27,11,0.61593,2.47026\n27,12,0.54385,2.59997\n27,13,0.47482,2.73007\n27,14,0.40933,2.8595\n27,15,0.3478,2.98721\n27,16,0.29062,3.11215\n27,17,0.23816,3.23327\n27,18,0.19072,3.34944\n27,19,0.14853,3.45967\n27,20,0.11188,3.56318\n27,21,0.08057,3.65833\n28,2,1.32844,1.47589\n28,3,1.25534,1.55964\n28,4,1.18051,1.65025\n28,5,1.10444,1.74728\n28,6,1.02762,1.85022\n28,7,0.95052,1.95851\n28,8,0.87366,2.07148\n28,9,0.79754,2.18844\n28,10,0.72265,2.30862\n28,11,0.64947,2.43122\n28,12,0.57848,2.5554\n28,13,0.51013,2.68025\n28,14,0.44486,2.80489\n28,15,0.38308,2.92838\n28,16,0.32517,3.04976\n28,17,0.27146,3.16812\n28,18,0.22228,3.28249\n28,19,0.17787,3.39189\n28,20,0.13843,3.49546\n28,21,0.10421,3.59248\n29,2,1.34054,1.48275\n29,3,1.26992,1.56312\n29,4,1.19762,1.64987\n29,5,1.12407,1.7426\n29,6,1.04971,1.84088\n29,7,0.97499,1.9442\n29,8,0.90036,2.05196\n29,9,0.82626,2.16358\n29,10,0.75316,2.27837\n29,11,0.68148,2.39562\n29,12,0.61166,2.51459\n29,13,0.54413,2.63447\n29,14,0.47929,2.75449\n29,15,0.41753,2.87381\n29,16,0.35918,2.9916\n29,17,0.30461,3.107\n29,18,0.25409,3.21917\n29,19,0.2079,3.32728\n29,20,0.16625,3.43042\n29,21,0.12931,3.52786\n30,2,1.35204,1.48936\n30,3,1.28373,1.56661\n30,4,1.2138,1.64981\n30,5,1.14262,1.7386\n30,6,1.0706,1.83259\n30,7,0.99815,1.93133\n30,8,0.92564,2.03432\n30,9,0.85351,2.14102\n30,10,0.78217,2.2508\n30,11,0.71202,2.36307\n30,12,0.64345,2.47714\n30,13,0.57685,2.59233\n30,14,0.51259,2.70793\n30,15,0.45105,2.82319\n30,16,0.39255,2.93738\n30,17,0.3374,3.04971\n30,18,0.2859,3.15946\n30,19,0.2383,3.26584\n30,20,0.19485,3.36811\n30,21,0.15572,3.46549\n31,2,1.36298,1.49574\n31,3,1.29685,1.57011\n31,4,1.22915,1.65002\n31,5,1.16021,1.73518\n31,6,1.0904,1.82522\n31,7,1.02008,1.91976\n31,8,0.94962,2.01834\n31,9,0.8794,2.12046\n31,10,0.80979,2.22562\n31,11,0.74115,2.33323\n31,12,0.67387,2.44273\n31,13,0.60828,2.55347\n31,14,0.54474,2.66484\n31,15,0.48358,2.77618\n31,16,0.42513,2.8868\n31,17,0.36966,2.99604\n31,18,0.31748,3.10322\n31,19,0.26882,3.20762\n31,20,0.22392,3.30859\n31,21,0.18298,3.40545\n32,2,1.3734,1.5019\n32,3,1.30932,1.57358\n32,4,1.24371,1.65046\n32,5,1.17688,1.73226\n32,6,1.10916,1.81867\n32,7,1.04088,1.90931\n32,8,0.97239,2.00381\n32,9,0.90401,2.10171\n32,10,0.83609,2.20255\n32,11,0.76897,2.30583\n32,12,0.70299,2.41102\n32,13,0.63847,2.51758\n32,14,0.57573,2.62493\n32,15,0.5151,2.73248\n32,16,0.45685,2.83963\n32,17,0.40129,2.94576\n32,18,0.34866,3.05028\n32,19,0.29923,3.15253\n32,20,0.25319,3.25193\n32,21,0.21078,3.34784\n33,2,1.38335,1.50784\n33,3,1.32119,1.57703\n33,4,1.25756,1.6511\n33,5,1.19272,1.72978\n33,6,1.12698,1.81282\n33,7,1.06065,1.89986\n33,8,0.99402,1.99057\n33,9,0.92743,2.08455\n33,10,0.86115,2.18137\n33,11,0.79554,2.28061\n33,12,0.73086,2.38177\n33,13,0.66745,2.48437\n33,14,0.60559,2.58789\n33,15,0.54558,2.69181\n33,16,0.48769,2.79558\n33,17,0.43219,2.89865\n33,18,0.37933,3.00046\n33,19,0.32935,3.10046\n33,20,0.28246,3.19808\n33,21,0.23887,3.29275\n34,2,1.39285,1.51358\n34,3,1.33251,1.58045\n34,4,1.27074,1.65189\n34,5,1.20779,1.7277\n34,6,1.14393,1.80758\n34,7,1.07944,1.89129\n34,8,1.01462,1.97849\n34,9,0.94973,2.06882\n34,10,0.88506,2.1619\n34,11,0.82091,2.25735\n34,12,0.75755,2.35473\n34,13,0.69527,2.45359\n34,14,0.63433,2.55348\n34,15,0.57503,2.65392\n34,16,0.5176,2.75442\n34,17,0.46231,2.85449\n34,18,0.40939,2.95361\n34,19,0.35907,3.05127\n34,20,0.31155,3.14697\n34,21,0.26704,3.2402\n35,2,1.40194,1.51914\n35,3,1.34332,1.58382\n35,4,1.2833,1.65282\n35,5,1.22214,1.72593\n35,6,1.16007,1.80292\n35,7,1.09735,1.88351\n35,8,1.03424,1.96743\n35,9,0.97099,2.05436\n35,10,0.90788,2.14395\n35,11,0.84516,2.23585\n35,12,0.78311,2.32966\n35,13,0.72197,2.42501\n35,14,0.662,2.52146\n35,15,0.60346,2.61858\n35,16,0.54659,2.71593\n35,17,0.49162,2.81306\n35,18,0.43878,2.90951\n35,19,0.38829,3.00481\n35,20,0.34034,3.09851\n35,21,0.29513,3.19013\n36,2,1.41065,1.52451\n36,3,1.35365,1.58716\n36,4,1.2953,1.65387\n36,5,1.23583,1.72447\n36,6,1.17545,1.79873\n36,7,1.11441,1.87643\n36,8,1.05294,1.9573\n36,9,0.99128,2.04104\n36,10,0.92967,2.12737\n36,11,0.86836,2.21594\n36,12,0.80759,2.30642\n36,13,0.74759,2.39844\n36,14,0.68861,2.49162\n36,15,0.63089,2.58557\n36,16,0.57463,2.6799\n36,17,0.52008,2.77418\n36,18,0.46745,2.868\n36,19,0.41692,2.96095\n36,20,0.36871,3.05259\n36,21,0.32299,3.14249\n37,2,1.419,1.52971\n37,3,1.36354,1.59044\n37,4,1.30678,1.65501\n37,5,1.24891,1.72327\n37,6,1.19014,1.79499\n37,7,1.13071,1.86998\n37,8,1.07081,1.94799\n37,9,1.01066,2.02876\n37,10,0.95051,2.11203\n37,11,0.89057,2.19749\n37,12,0.83105,2.28481\n37,13,0.77219,2.37369\n37,14,0.71421,2.46378\n37,15,0.65734,2.55471\n37,16,0.60177,2.64613\n37,17,0.54771,2.73765\n37,18,0.49537,2.82891\n37,19,0.44494,2.91951\n37,20,0.39661,3.00907\n37,21,0.35054,3.09719\n38,2,1.42702,1.53475\n38,3,1.37301,1.59368\n38,4,1.31774,1.65625\n38,5,1.2614,1.72229\n38,6,1.20418,1.79164\n38,7,1.14627,1.86409\n38,8,1.08787,1.93942\n38,9,1.02919,2.01742\n38,10,0.97045,2.09782\n38,11,0.91183,2.18033\n38,12,0.85356,2.2647\n38,13,0.79583,2.35061\n38,14,0.73886,2.43775\n38,15,0.68284,2.52581\n38,16,0.62799,2.61444\n38,17,0.57448,2.70332\n38,18,0.52253,2.79207\n38,19,0.47229,2.88036\n38,20,0.42396,2.96784\n38,21,0.37769,3.05412\n39,2,1.43473,1.53963\n39,3,1.3821,1.59686\n39,4,1.32827,1.65754\n39,5,1.27338,1.72152\n39,6,1.21761,1.78863\n39,7,1.16116,1.8587\n39,8,1.10419,1.93153\n39,9,1.04692,2.00692\n39,10,0.98953,2.0846\n39,11,0.9322,2.16437\n39,12,0.87514,2.24594\n39,13,0.81853,2.32904\n39,14,0.76257,2.4134\n39,15,0.70743,2.49872\n39,16,0.65333,2.58469\n39,17,0.60044,2.671\n39,18,0.54891,2.75733\n39,19,0.49896,2.84336\n39,20,0.45072,2.92876\n39,21,0.40437,3.0132\n40,2,1.44214,1.54436\n40,3,1.39083,1.59999\n40,4,1.33835,1.65889\n40,5,1.28484,1.72092\n40,6,1.23047,1.78594\n40,7,1.17541,1.85378\n40,8,1.11983,1.92426\n40,9,1.06391,1.99717\n40,10,1.00782,2.07233\n40,11,0.95174,2.1495\n40,12,0.89585,2.22843\n40,13,0.84035,2.30888\n40,14,0.78539,2.3906\n40,15,0.73115,2.4733\n40,16,0.67782,2.55672\n40,17,0.62556,2.64056\n40,18,0.57454,2.72455\n40,19,0.52492,2.80836\n40,20,0.47687,2.89172\n40,21,0.43054,2.97431\n41,2,1.44927,1.54895\n41,3,1.39922,1.60307\n41,4,1.34803,1.66028\n41,5,1.29584,1.72048\n41,6,1.2428,1.78353\n41,7,1.18907,1.84926\n41,8,1.13481,1.91753\n41,9,1.08019,1.98813\n41,10,1.02536,2.06089\n41,11,0.9705,2.13561\n41,12,0.91576,2.21204\n41,13,0.86132,2.28998\n41,14,0.80736,2.36919\n41,15,0.75402,2.44941\n41,16,0.70146,2.53039\n41,17,0.64987,2.61187\n41,18,0.5994,2.69358\n41,19,0.55018,2.77525\n41,20,0.50238,2.8566\n41,21,0.45615,2.93734\n42,2,1.45615,1.5534\n42,3,1.4073,1.60608\n42,4,1.35733,1.66172\n42,5,1.3064,1.72019\n42,6,1.25463,1.78137\n42,7,1.20218,1.84512\n42,8,1.14918,1.9113\n42,9,1.09581,1.97972\n42,10,1.04219,2.05023\n42,11,0.98851,2.12262\n42,12,0.93489,2.1967\n42,13,0.88151,2.27227\n42,14,0.82852,2.34909\n42,15,0.77607,2.42694\n42,16,0.72431,2.50558\n42,17,0.67341,2.5848\n42,18,0.6235,2.66432\n42,19,0.57474,2.74389\n42,20,0.52726,2.82328\n42,21,0.48121,2.9022\n43,2,1.46278,1.55773\n43,3,1.41507,1.60905\n43,4,1.36629,1.66319\n43,5,1.31655,1.72002\n43,6,1.266,1.77944\n43,7,1.21476,1.84132\n43,8,1.16298,1.90552\n43,9,1.1108,1.97189\n43,10,1.05837,2.04027\n43,11,1.00581,2.11047\n43,12,0.95328,2.18231\n43,13,0.90093,2.25562\n43,14,0.84891,2.33017\n43,15,0.79734,2.40577\n43,16,0.74639,2.4822\n43,17,0.69619,2.55922\n43,18,0.64688,2.63664\n43,19,0.5986,2.71419\n43,20,0.55149,2.79164\n43,21,0.50568,2.86878\n44,2,1.4692,1.56193\n44,3,1.42257,1.61196\n44,4,1.3749,1.66467\n44,5,1.32631,1.71996\n44,6,1.27692,1.77772\n44,7,1.22685,1.83784\n44,8,1.17624,1.90017\n44,9,1.12522,1.9646\n44,10,1.0739,2.03095\n44,11,1.02245,2.09907\n44,12,0.97099,2.16881\n44,13,0.91964,2.23997\n44,14,0.86856,2.31237\n44,15,0.81787,2.38581\n44,16,0.76771,2.46011\n44,17,0.71822,2.53505\n44,18,0.66953,2.61043\n44,19,0.62177,2.68601\n44,20,0.57507,2.76161\n44,21,0.52954,2.83698\n45,2,1.47538,1.56602\n45,3,1.4298,1.61482\n45,4,1.3832,1.66618\n45,5,1.33571,1.71999\n45,6,1.28744,1.77618\n45,7,1.23849,1.83462\n45,8,1.18899,1.8952\n45,9,1.13907,1.95778\n45,10,1.08886,2.02222\n45,11,1.03846,2.08839\n45,12,0.98802,2.15611\n45,13,0.93765,2.22524\n45,14,0.8875,2.29558\n45,15,0.83769,2.36698\n45,16,0.78833,2.43924\n45,17,0.73955,2.51218\n45,18,0.69149,2.58559\n45,19,0.64427,2.65929\n45,20,0.59801,2.73306\n45,21,0.55282,2.80672\n46,2,1.48136,1.56999\n46,3,1.43677,1.61763\n46,4,1.39121,1.66769\n46,5,1.34477,1.72012\n46,6,1.29756,1.77482\n46,7,1.24969,1.83167\n46,8,1.20127,1.89058\n46,9,1.15242,1.95141\n46,10,1.10325,2.01404\n46,11,1.05388,2.07834\n46,12,1.00443,2.14416\n46,13,0.95503,2.21134\n46,14,0.90578,2.27974\n46,15,0.85681,2.34918\n46,16,0.80825,2.4195\n46,17,0.7602,2.49051\n46,18,0.71278,2.56205\n46,19,0.66611,2.63391\n46,20,0.62032,2.70593\n46,21,0.5755,2.7779\n47,2,1.48715,1.57386\n47,3,1.44352,1.62038\n47,4,1.39894,1.66923\n47,5,1.3535,1.72033\n47,6,1.30731,1.77361\n47,7,1.26047,1.82895\n47,8,1.21309,1.88627\n47,9,1.16526,1.94545\n47,10,1.1171,2.00636\n47,11,1.06873,2.06889\n47,12,1.02026,2.1329\n47,13,0.97178,2.19824\n47,14,0.92342,2.26478\n47,15,0.87529,2.33235\n47,16,0.82751,2.4008\n47,17,0.78018,2.46998\n47,18,0.73341,2.5397\n47,19,0.68732,2.6098\n47,20,0.642,2.68011\n47,21,0.59759,2.75044\n48,2,1.49275,1.57762\n48,3,1.45004,1.62308\n48,4,1.4064,1.67076\n48,5,1.36192,1.72061\n48,6,1.31672,1.77253\n48,7,1.27087,1.82645\n48,8,1.22447,1.88226\n48,9,1.17764,1.93987\n48,10,1.13046,1.99915\n48,11,1.08306,2.05999\n48,12,1.03552,2.12227\n48,13,0.98794,2.18586\n48,14,0.94045,2.25062\n48,15,0.89314,2.31641\n48,16,0.84614,2.38309\n48,17,0.79951,2.45049\n48,18,0.7534,2.51847\n48,19,0.70789,2.58687\n48,20,0.66309,2.65552\n48,21,0.61909,2.72427\n49,2,1.49819,1.58129\n49,3,1.45635,1.62573\n49,4,1.41362,1.6723\n49,5,1.37007,1.72095\n49,6,1.3258,1.77159\n49,7,1.2809,1.82415\n49,8,1.23546,1.87852\n49,9,1.18958,1.93463\n49,10,1.14336,1.99236\n49,11,1.09687,2.0516\n49,12,1.05024,2.11224\n49,13,1.00354,2.17415\n49,14,0.9569,2.23723\n49,15,0.9104,2.30131\n49,16,0.86415,2.36628\n49,17,0.81824,2.43199\n49,18,0.77278,2.49829\n49,19,0.72786,2.56505\n49,20,0.68358,2.63211\n49,21,0.64003,2.6993\n50,2,1.50345,1.58486\n50,3,1.46246,1.62833\n50,4,1.42059,1.67385\n50,5,1.37793,1.72135\n50,6,1.33457,1.77077\n50,7,1.29059,1.82203\n50,8,1.24607,1.87504\n50,9,1.2011,1.92972\n50,10,1.15579,1.98597\n50,11,1.11021,2.04368\n50,12,1.06445,2.10276\n50,13,1.01862,2.16307\n50,14,0.9728,2.22452\n50,15,0.92709,2.28698\n50,16,0.88159,2.35032\n50,17,0.83638,2.4144\n50,18,0.79156,2.4791\n50,19,0.74723,2.54428\n50,20,0.70348,2.60978\n50,21,0.6604,2.67548\n51,2,1.50856,1.58835\n51,3,1.46838,1.63088\n51,4,1.42734,1.67538\n51,5,1.38554,1.72179\n51,6,1.34305,1.77005\n51,7,1.29995,1.82007\n51,8,1.25632,1.87178\n51,9,1.21224,1.9251\n51,10,1.1678,1.97994\n51,11,1.12308,2.0362\n51,12,1.07818,2.09378\n51,13,1.03319,2.15258\n51,14,0.98817,2.21249\n51,15,0.94324,2.27338\n51,16,0.89847,2.33515\n51,17,0.85396,2.39767\n51,18,0.80978,2.46083\n51,19,0.76604,2.52448\n51,20,0.72282,2.58848\n51,21,0.68021,2.65272\n52,2,1.51352,1.59174\n52,3,1.4741,1.63339\n52,4,1.43388,1.67692\n52,5,1.3929,1.72228\n52,6,1.35124,1.76942\n52,7,1.30899,1.81827\n52,8,1.26622,1.86874\n52,9,1.22299,1.92076\n52,10,1.17941,1.97426\n52,11,1.13553,2.02913\n52,12,1.09146,2.08528\n52,13,1.04727,2.14263\n52,14,1.00304,2.20106\n52,15,0.95887,2.26046\n52,16,0.91481,2.32074\n52,17,0.87099,2.38176\n52,18,0.82745,2.44341\n52,19,0.78431,2.50559\n52,20,0.74163,2.56816\n52,21,0.69949,2.63099\n53,2,1.51833,1.59505\n53,3,1.47967,1.63585\n53,4,1.44022,1.67845\n53,5,1.40002,1.72282\n53,6,1.35918,1.7689\n53,7,1.31774,1.81661\n53,8,1.27579,1.8659\n53,9,1.2334,1.91668\n53,10,1.19063,1.96889\n53,11,1.14757,2.02244\n53,12,1.1043,2.07723\n53,13,1.0609,2.13318\n53,14,1.01743,2.19019\n53,15,0.97399,2.24817\n53,16,0.93065,2.307\n53,17,0.88749,2.36659\n53,18,0.84459,2.42682\n53,19,0.80204,2.48757\n53,20,0.7599,2.54874\n53,21,0.71826,2.61021\n54,2,1.523,1.59829\n54,3,1.48506,1.63825\n54,4,1.44636,1.67998\n54,5,1.40693,1.72339\n54,6,1.36687,1.76844\n54,7,1.32622,1.81508\n54,8,1.28506,1.86324\n54,9,1.24345,1.91283\n54,10,1.20149,1.96381\n54,11,1.15921,2.01609\n54,12,1.11672,2.06959\n54,13,1.07408,2.1242\n54,14,1.03136,2.17987\n54,15,0.98864,2.23647\n54,16,0.946,2.29392\n54,17,0.90349,2.35213\n54,18,0.86122,2.41097\n54,19,0.81925,2.47036\n54,20,0.77766,2.53019\n54,21,0.73651,2.59033\n55,2,1.52755,1.60144\n55,3,1.49031,1.64062\n55,4,1.45232,1.68149\n55,5,1.41362,1.72399\n55,6,1.37431,1.76807\n55,7,1.33442,1.81368\n55,8,1.29403,1.86074\n55,9,1.25319,1.90921\n55,10,1.21199,1.95902\n55,11,1.17049,2.01008\n55,12,1.12875,2.06233\n55,13,1.08685,2.11568\n55,14,1.04485,2.17003\n55,15,1.00284,2.22532\n55,16,0.96087,2.28146\n55,17,0.91902,2.33833\n55,18,0.87736,2.39585\n55,19,0.83597,2.45392\n55,20,0.79492,2.51244\n55,21,0.75427,2.57131\n56,2,1.53197,1.60452\n56,3,1.49541,1.64295\n56,4,1.4581,1.683\n56,5,1.42012,1.72461\n56,6,1.38152,1.76776\n56,7,1.34237,1.81238\n56,8,1.30271,1.85841\n56,9,1.26263,1.90579\n56,10,1.22217,1.95448\n56,11,1.18141,2.00438\n56,12,1.1404,2.05542\n56,13,1.09922,2.10755\n56,14,1.05793,2.16067\n56,15,1.01659,2.2147\n56,16,0.9753,2.26956\n56,17,0.93408,2.32515\n56,18,0.89304,2.3814\n56,19,0.85222,2.4382\n56,20,0.8117,2.49546\n56,21,0.77155,2.55309\n57,2,1.53628,1.60754\n57,3,1.50036,1.64524\n57,4,1.46372,1.68449\n57,5,1.42642,1.72526\n57,6,1.38852,1.76751\n57,7,1.35008,1.81119\n57,8,1.31114,1.85622\n57,9,1.27177,1.90257\n57,10,1.23203,1.95018\n57,11,1.19198,1.99896\n57,12,1.15168,2.04887\n57,13,1.11121,2.09982\n57,14,1.0706,2.15175\n57,15,1.02994,2.20456\n57,16,0.98929,2.2582\n57,17,0.94871,2.31257\n57,18,0.90825,2.36758\n57,19,0.868,2.42316\n57,20,0.82802,2.4792\n57,21,0.78836,2.53563\n58,2,1.54047,1.61048\n58,3,1.50517,1.64747\n58,4,1.46918,1.68598\n58,5,1.43254,1.72594\n58,6,1.39532,1.76733\n58,7,1.35755,1.81009\n58,8,1.31931,1.85418\n58,9,1.28063,1.89954\n58,10,1.24159,1.9461\n58,11,1.20224,1.99382\n58,12,1.16263,2.04262\n58,13,1.12283,2.09245\n58,14,1.08289,2.14323\n58,15,1.04288,2.19489\n58,16,1.00287,2.24735\n58,17,0.96289,2.30054\n58,18,0.92304,2.35436\n58,19,0.88335,2.40875\n58,20,0.84389,2.46362\n58,21,0.80473,2.51889\n59,2,1.54455,1.61336\n59,3,1.50985,1.64967\n59,4,1.47448,1.68745\n59,5,1.43848,1.72663\n59,6,1.40191,1.7672\n59,7,1.36481,1.80908\n59,8,1.32723,1.85226\n59,9,1.28923,1.89665\n59,10,1.25086,1.94223\n59,11,1.21218,1.98893\n59,12,1.17325,2.03668\n59,13,1.1341,2.08543\n59,14,1.09482,2.1351\n59,15,1.05545,2.18564\n59,16,1.01605,2.23698\n59,17,0.97668,2.28902\n59,18,0.93739,2.34171\n59,19,0.89826,2.39495\n59,20,0.85932,2.44869\n59,21,0.82065,2.50283\n60,2,1.54853,1.61617\n60,3,1.51442,1.65184\n60,4,1.47965,1.68891\n60,5,1.44427,1.72735\n60,6,1.40832,1.76711\n60,7,1.37186,1.80817\n60,8,1.33493,1.85045\n60,9,1.29758,1.89393\n60,10,1.25987,1.93856\n60,11,1.22183,1.98427\n60,12,1.18354,2.03101\n60,13,1.14505,2.07873\n60,14,1.1064,2.12734\n60,15,1.06764,2.17681\n60,16,1.02885,2.22705\n60,17,0.99007,2.278\n60,18,0.95135,2.32958\n60,19,0.91276,2.38173\n60,20,0.87435,2.43437\n60,21,0.83616,2.48742\n61,2,1.5524,1.61892\n61,3,1.51886,1.65396\n61,4,1.48468,1.69035\n61,5,1.44989,1.72808\n61,6,1.41455,1.76708\n61,7,1.37871,1.80732\n61,8,1.3424,1.84876\n61,9,1.30568,1.89137\n61,10,1.2686,1.93507\n61,11,1.2312,1.97984\n61,12,1.19355,2.0256\n61,13,1.15567,2.07232\n61,14,1.11763,2.11992\n61,15,1.0795,2.16835\n61,16,1.04129,2.21755\n61,17,1.00309,2.26744\n61,18,0.96492,2.31796\n61,19,0.92686,2.36904\n61,20,0.88896,2.42062\n61,21,0.85126,2.47262\n62,2,1.55619,1.62161\n62,3,1.52318,1.65605\n62,4,1.48957,1.6918\n62,5,1.45536,1.72881\n62,6,1.42061,1.76708\n62,7,1.38536,1.80655\n62,8,1.34967,1.84718\n62,9,1.31356,1.88893\n62,10,1.27709,1.93176\n62,11,1.24031,1.97561\n62,12,1.20326,2.02044\n62,13,1.16599,2.0662\n62,14,1.12856,2.11282\n62,15,1.091,2.16026\n62,16,1.05338,2.20844\n62,17,1.01573,2.25732\n62,18,0.97812,2.30681\n62,19,0.94058,2.35687\n62,20,0.90319,2.40742\n62,21,0.86597,2.4584\n63,2,1.55987,1.62425\n63,3,1.52741,1.6581\n63,4,1.49433,1.69321\n63,5,1.46068,1.72957\n63,6,1.4265,1.76712\n63,7,1.39183,1.80584\n63,8,1.35672,1.84569\n63,9,1.32121,1.88663\n63,10,1.28534,1.9286\n63,11,1.24915,1.97159\n63,12,1.21269,2.01552\n63,13,1.17602,2.06035\n63,14,1.13917,2.10603\n63,15,1.10219,2.1525\n63,16,1.06512,2.19971\n63,17,1.02803,2.24761\n63,18,0.99096,2.29612\n63,19,0.95394,2.34518\n63,20,0.91703,2.39474\n63,21,0.88029,2.44473\n64,2,1.56348,1.62683\n64,3,1.53152,1.66011\n64,4,1.49897,1.69463\n64,5,1.46587,1.73033\n64,6,1.43223,1.7672\n64,7,1.39813,1.8052\n64,8,1.36359,1.84429\n64,9,1.32865,1.88444\n64,10,1.29336,1.92561\n64,11,1.25775,1.96775\n64,12,1.22188,2.01081\n64,13,1.18576,2.05475\n64,14,1.14949,2.09952\n64,15,1.11306,2.14507\n64,16,1.07655,2.19134\n64,17,1.04,2.23829\n64,18,1.00345,2.28584\n64,19,0.96694,2.33395\n64,20,0.93053,2.38255\n64,21,0.89425,2.43159\n65,2,1.56699,1.62936\n65,3,1.53553,1.6621\n65,4,1.50349,1.69602\n65,5,1.47092,1.7311\n65,6,1.43782,1.76731\n65,7,1.40426,1.80462\n65,8,1.37027,1.84298\n65,9,1.33589,1.88238\n65,10,1.30115,1.92276\n65,11,1.26611,1.96408\n65,12,1.2308,2.00631\n65,13,1.19525,2.04939\n65,14,1.15952,2.09329\n65,15,1.12364,2.13795\n65,16,1.08767,2.18331\n65,17,1.05165,2.22934\n65,18,1.0156,2.27597\n65,19,0.9796,2.32315\n65,20,0.94367,2.37083\n65,21,0.90785,2.41894\n66,2,1.57043,1.63184\n66,3,1.53945,1.66404\n66,4,1.5079,1.6974\n66,5,1.47583,1.73188\n66,6,1.44326,1.76745\n66,7,1.41023,1.80409\n66,8,1.37677,1.84175\n66,9,1.34293,1.88041\n66,10,1.30874,1.92004\n66,11,1.27424,1.96058\n66,12,1.23947,2.002\n66,13,1.20447,2.04426\n66,14,1.16928,2.08731\n66,15,1.13394,2.1311\n66,16,1.0985,2.17559\n66,17,1.06298,2.22074\n66,18,1.02744,2.26648\n66,19,0.99192,2.31277\n66,20,0.95646,2.35954\n66,21,0.92111,2.40676\n67,2,1.57378,1.63427\n67,3,1.54328,1.66596\n67,4,1.51221,1.69877\n67,5,1.48063,1.73267\n67,6,1.44856,1.76762\n67,7,1.41604,1.8036\n67,8,1.38311,1.8406\n67,9,1.34979,1.87856\n67,10,1.31613,1.91744\n67,11,1.28216,1.95723\n67,12,1.24792,1.99787\n67,13,1.21345,2.03934\n67,14,1.17878,2.08158\n67,15,1.14396,2.12453\n67,16,1.10903,2.16819\n67,17,1.07401,2.21248\n67,18,1.03897,2.25735\n67,19,1.00394,2.30277\n67,20,0.96894,2.34868\n67,21,0.93402,2.39503\n68,2,1.57706,1.63665\n68,3,1.54701,1.66784\n68,4,1.51642,1.70011\n68,5,1.48531,1.73345\n68,6,1.45373,1.76781\n68,7,1.42171,1.80318\n68,8,1.38928,1.83952\n68,9,1.35647,1.87679\n68,10,1.32332,1.91497\n68,11,1.28987,1.95403\n68,12,1.25614,1.99393\n68,13,1.22218,2.03462\n68,14,1.18803,2.07606\n68,15,1.15372,2.11823\n68,16,1.11929,2.16106\n68,17,1.08477,2.20453\n68,18,1.05021,2.24857\n68,19,1.01563,2.29315\n68,20,0.98109,2.33822\n68,21,0.94663,2.38371\n69,2,1.58027,1.63898\n69,3,1.55066,1.6697\n69,4,1.52052,1.70146\n69,5,1.48988,1.73425\n69,6,1.45877,1.76803\n69,7,1.42723,1.80279\n69,8,1.39529,1.83849\n69,9,1.36298,1.87512\n69,10,1.33032,1.91262\n69,11,1.29737,1.95098\n69,12,1.26415,1.99014\n69,13,1.23069,2.03009\n69,14,1.19704,2.07078\n69,15,1.16322,2.11216\n69,16,1.12928,2.15421\n69,17,1.09524,2.19688\n69,18,1.06115,2.24012\n69,19,1.02704,2.28388\n69,20,0.99295,2.32813\n69,21,0.95892,2.37281\n70,2,1.58341,1.64127\n70,3,1.55422,1.67152\n70,4,1.52452,1.70278\n70,5,1.49434,1.73505\n70,6,1.46369,1.76827\n70,7,1.43262,1.80245\n70,8,1.40115,1.83754\n70,9,1.36932,1.87353\n70,10,1.33716,1.91037\n70,11,1.30469,1.94805\n70,12,1.27196,1.98652\n70,13,1.23899,2.02574\n70,14,1.20582,2.06569\n70,15,1.17249,2.10634\n70,16,1.13902,2.14762\n70,17,1.10544,2.18951\n70,18,1.07182,2.23197\n70,19,1.03816,2.27495\n70,20,1.00451,2.3184\n70,21,0.97091,2.3623\n71,2,1.58648,1.64352\n71,3,1.55771,1.67331\n71,4,1.52844,1.70409\n71,5,1.49868,1.73584\n71,6,1.46849,1.76854\n71,7,1.43787,1.80214\n71,8,1.40686,1.83664\n71,9,1.37551,1.87202\n71,10,1.34381,1.90823\n71,11,1.31182,1.94524\n71,12,1.27957,1.98304\n71,13,1.24707,2.02157\n71,14,1.21437,2.06081\n71,15,1.1815,2.10073\n71,16,1.14851,2.14128\n71,17,1.11539,2.18242\n71,18,1.08222,2.22412\n71,19,1.049,2.26634\n71,20,1.01579,2.30903\n71,21,0.98261,2.35215\n72,2,1.58949,1.64571\n72,3,1.56112,1.67507\n72,4,1.53226,1.70539\n72,5,1.50293,1.73664\n72,6,1.47317,1.76881\n72,7,1.443,1.80187\n72,8,1.41245,1.83581\n72,9,1.38154,1.87059\n72,10,1.3503,1.90618\n72,11,1.31877,1.94256\n72,12,1.28698,1.9797\n72,13,1.25495,2.01756\n72,14,1.22272,2.05611\n72,15,1.19031,2.09532\n72,16,1.15776,2.13516\n72,17,1.1251,2.17558\n72,18,1.09237,2.21655\n72,19,1.05959,2.25803\n72,20,1.0268,2.29997\n72,21,0.99403,2.34236\n73,2,1.59243,1.64788\n73,3,1.56446,1.67681\n73,4,1.53599,1.70667\n73,5,1.50709,1.73745\n73,6,1.47775,1.76911\n73,7,1.44801,1.80164\n73,8,1.41789,1.83502\n73,9,1.38743,1.86923\n73,10,1.35663,1.90422\n73,11,1.32556,1.93999\n73,12,1.29421,1.97649\n73,13,1.26262,2.0137\n73,14,1.23084,2.05159\n73,15,1.19889,2.09013\n73,16,1.16678,2.12927\n73,17,1.13456,2.16899\n73,18,1.10226,2.20925\n73,19,1.06991,2.25001\n73,20,1.03753,2.29124\n73,21,1.00517,2.3329\n74,2,1.5953,1.65001\n74,3,1.56772,1.67852\n74,4,1.53966,1.70793\n74,5,1.51115,1.73825\n74,6,1.48222,1.76943\n74,7,1.45289,1.80144\n74,8,1.42321,1.83429\n74,9,1.39316,1.86793\n74,10,1.36281,1.90235\n74,11,1.33217,1.93752\n74,12,1.30127,1.97341\n74,13,1.27013,2.01\n74,14,1.23878,2.04724\n74,15,1.20725,2.08511\n74,16,1.17559,2.12359\n74,17,1.14379,2.16263\n74,18,1.11192,2.2022\n74,19,1.07998,2.24227\n74,20,1.04801,2.2828\n74,21,1.01605,2.32375\n75,2,1.59813,1.65209\n75,3,1.57091,1.6802\n75,4,1.54323,1.7092\n75,5,1.51511,1.73904\n75,6,1.48659,1.76975\n75,7,1.45767,1.80127\n75,8,1.4284,1.8336\n75,9,1.39877,1.8667\n75,10,1.36884,1.90057\n75,11,1.33863,1.93516\n75,12,1.30815,1.97046\n75,13,1.27744,2.00643\n75,14,1.24652,2.04304\n75,15,1.21542,2.08028\n75,16,1.18418,2.11811\n75,17,1.15281,2.15649\n75,18,1.12135,2.1954\n75,19,1.08982,2.2348\n75,20,1.05825,2.27465\n75,21,1.02668,2.31492\n76,2,1.6009,1.65413\n76,3,1.57404,1.68185\n76,4,1.54673,1.71043\n76,5,1.519,1.73985\n76,6,1.49086,1.77009\n76,7,1.46233,1.80113\n76,8,1.43346,1.83295\n76,9,1.40425,1.86553\n76,10,1.37473,1.89886\n76,11,1.34493,1.93288\n76,12,1.31488,1.96761\n76,13,1.28458,2.00299\n76,14,1.25408,2.039\n76,15,1.2234,2.07563\n76,16,1.19257,2.11283\n76,17,1.16161,2.15057\n76,18,1.13056,2.18883\n76,19,1.09942,2.22757\n76,20,1.06825,2.26676\n76,21,1.03706,2.30638\n77,2,1.60361,1.65614\n77,3,1.5771,1.68348\n77,4,1.55015,1.71166\n77,5,1.52279,1.74065\n77,6,1.49503,1.77044\n77,7,1.4669,1.80102\n77,8,1.43842,1.83235\n77,9,1.40961,1.86443\n77,10,1.38048,1.89722\n77,11,1.35108,1.93071\n77,12,1.32143,1.96487\n77,13,1.29155,1.99969\n77,14,1.26146,2.03511\n77,15,1.23119,2.07113\n77,16,1.20076,2.10772\n77,17,1.1702,2.14485\n77,18,1.13954,2.18248\n77,19,1.10881,2.22059\n77,20,1.07801,2.25914\n77,21,1.04721,2.29811\n78,2,1.60626,1.65812\n78,3,1.5801,1.68509\n78,4,1.55351,1.71287\n78,5,1.52651,1.74145\n78,6,1.49912,1.77081\n78,7,1.47136,1.80093\n78,8,1.44325,1.83178\n78,9,1.41483,1.86337\n78,10,1.3861,1.89565\n78,11,1.35711,1.92862\n78,12,1.32785,1.96224\n78,13,1.29836,1.9965\n78,14,1.26867,2.03136\n78,15,1.23879,2.0668\n78,16,1.20876,2.10279\n78,17,1.1786,2.13932\n78,18,1.14832,2.17634\n78,19,1.11797,2.21384\n78,20,1.08756,2.25177\n78,21,1.05712,2.29011\n79,2,1.60887,1.66006\n79,3,1.58304,1.68667\n79,4,1.55679,1.71407\n79,5,1.53015,1.74225\n79,6,1.50312,1.77118\n79,7,1.47572,1.80086\n79,8,1.448,1.83126\n79,9,1.41994,1.86237\n79,10,1.3916,1.89416\n79,11,1.36299,1.92661\n79,12,1.33411,1.9597\n79,13,1.30501,1.99342\n79,14,1.27571,2.02773\n79,15,1.24622,2.06261\n79,16,1.21658,2.09804\n79,17,1.18679,2.13398\n79,18,1.1569,2.17041\n79,19,1.12693,2.2073\n79,20,1.09689,2.24464\n79,21,1.0668,2.28237\n80,2,1.61143,1.66197\n80,3,1.58592,1.68823\n80,4,1.56001,1.71526\n80,5,1.5337,1.74304\n80,6,1.50703,1.77156\n80,7,1.47999,1.80081\n80,8,1.45262,1.83077\n80,9,1.42495,1.86142\n80,10,1.39698,1.89272\n80,11,1.36873,1.92469\n80,12,1.34024,1.95727\n80,13,1.31151,1.99046\n80,14,1.28259,2.02423\n80,15,1.25348,2.05857\n80,16,1.22422,2.09343\n80,17,1.19481,2.12881\n80,18,1.16529,2.16467\n80,19,1.13568,2.20099\n80,20,1.106,2.23772\n80,21,1.07628,2.27487\n81,2,1.61393,1.66385\n81,3,1.58875,1.68976\n81,4,1.56316,1.71643\n81,5,1.53719,1.74384\n81,6,1.51085,1.77196\n81,7,1.48417,1.80079\n81,8,1.45715,1.83031\n81,9,1.42984,1.86051\n81,10,1.40223,1.89135\n81,11,1.37434,1.92282\n81,12,1.34622,1.95492\n81,13,1.31787,1.9876\n81,14,1.28931,2.02085\n81,15,1.26058,2.05466\n81,16,1.23168,2.08898\n81,17,1.20264,2.12381\n81,18,1.17348,2.15911\n81,19,1.14424,2.19486\n81,20,1.11491,2.23103\n81,21,1.08555,2.2676\n82,2,1.61639,1.66569\n82,3,1.59152,1.69128\n82,4,1.56625,1.71759\n82,5,1.5406,1.74462\n82,6,1.51461,1.77237\n82,7,1.48826,1.80079\n82,8,1.46159,1.82989\n82,9,1.43462,1.85964\n82,10,1.40736,1.89003\n82,11,1.37984,1.92105\n82,12,1.35207,1.95265\n82,13,1.32408,1.98485\n82,14,1.2959,2.0176\n82,15,1.26752,2.05088\n82,16,1.23898,2.08469\n82,17,1.2103,2.11897\n82,18,1.1815,2.15373\n82,19,1.1526,2.18894\n82,20,1.12364,2.22455\n82,21,1.09461,2.26056\n83,2,1.6188,1.66751\n83,3,1.59423,1.69276\n83,4,1.56928,1.71874\n83,5,1.54395,1.74541\n83,6,1.51828,1.77278\n83,7,1.49226,1.8008\n83,8,1.46593,1.8295\n83,9,1.4393,1.85882\n83,10,1.41239,1.88877\n83,11,1.38522,1.91933\n83,12,1.3578,1.95048\n83,13,1.33017,1.98219\n83,14,1.30233,2.01444\n83,15,1.2743,2.04723\n83,16,1.24612,2.08052\n83,17,1.21779,2.11429\n83,18,1.18934,2.14853\n83,19,1.1608,2.1832\n83,20,1.13217,2.21827\n83,21,1.10349,2.25373\n84,2,1.62118,1.66929\n84,3,1.59691,1.69424\n84,4,1.57225,1.71987\n84,5,1.54723,1.74619\n84,6,1.52188,1.77318\n84,7,1.49618,1.80084\n84,8,1.47018,1.82912\n84,9,1.44388,1.85804\n84,10,1.41731,1.88756\n84,11,1.39048,1.91768\n84,12,1.3634,1.94837\n84,13,1.33611,1.97962\n84,14,1.30862,2.0114\n84,15,1.28094,2.0437\n84,16,1.2531,2.07649\n84,17,1.22512,2.10976\n84,18,1.19701,2.14348\n84,19,1.1688,2.17762\n84,20,1.14051,2.21218\n84,21,1.11215,2.24712\n85,2,1.6235,1.67105\n85,3,1.59952,1.69568\n85,4,1.57516,1.721\n85,5,1.55045,1.74697\n85,6,1.5254,1.77361\n85,7,1.50003,1.80089\n85,8,1.47434,1.82879\n85,9,1.44837,1.8573\n85,10,1.42212,1.88641\n85,11,1.39562,1.9161\n85,12,1.36889,1.94635\n85,13,1.34194,1.97714\n85,14,1.31477,2.00845\n85,15,1.28744,2.04028\n85,16,1.25993,2.07259\n85,17,1.23229,2.10536\n85,18,1.20451,2.13858\n85,19,1.17664,2.17223\n85,20,1.14868,2.20627\n85,21,1.12064,2.2407\n86,2,1.62579,1.67277\n86,3,1.60209,1.69711\n86,4,1.57802,1.7221\n86,5,1.5536,1.74775\n86,6,1.52885,1.77404\n86,7,1.50378,1.80095\n86,8,1.47842,1.82848\n86,9,1.45277,1.85659\n86,10,1.42684,1.8853\n86,11,1.40066,1.91457\n86,12,1.37426,1.94439\n86,13,1.34762,1.97474\n86,14,1.32081,2.00561\n86,15,1.29379,2.03697\n86,16,1.26662,2.06881\n86,17,1.23931,2.10111\n86,18,1.21187,2.13384\n86,19,1.18432,2.167\n86,20,1.15667,2.20054\n86,21,1.12896,2.23446\n87,2,1.62804,1.67448\n87,3,1.60461,1.69851\n87,4,1.58083,1.7232\n87,5,1.5567,1.74852\n87,6,1.53224,1.77448\n87,7,1.50748,1.80103\n87,8,1.48242,1.82819\n87,9,1.45707,1.85592\n87,10,1.43146,1.88423\n87,11,1.40561,1.9131\n87,12,1.37951,1.9425\n87,13,1.3532,1.97243\n87,14,1.32671,2.00285\n87,15,1.30002,2.03377\n87,16,1.27317,2.06515\n87,17,1.24617,2.09699\n87,18,1.21906,2.12925\n87,19,1.19183,2.16192\n87,20,1.1645,2.19498\n87,21,1.1371,2.22841\n88,2,1.63024,1.67615\n88,3,1.60709,1.6999\n88,4,1.58358,1.72429\n88,5,1.55974,1.74929\n88,6,1.53557,1.77491\n88,7,1.51109,1.80112\n88,8,1.48633,1.82792\n88,9,1.46129,1.85529\n88,10,1.43599,1.88321\n88,11,1.41044,1.91168\n88,12,1.38466,1.94068\n88,13,1.35867,1.97019\n88,14,1.33248,2.00018\n88,15,1.30611,2.03067\n88,16,1.27958,2.0616\n88,17,1.2529,2.09298\n88,18,1.22609,2.12478\n88,19,1.19918,2.15699\n88,20,1.17217,2.18959\n88,21,1.14507,2.22254\n89,2,1.63242,1.6778\n89,3,1.60951,1.70127\n89,4,1.58628,1.72536\n89,5,1.56271,1.75006\n89,6,1.53883,1.77535\n89,7,1.51465,1.80123\n89,8,1.49017,1.82768\n89,9,1.46542,1.85469\n89,10,1.44042,1.88223\n89,11,1.41518,1.91032\n89,12,1.3897,1.93892\n89,13,1.36402,1.96802\n89,14,1.33814,1.9976\n89,15,1.31208,2.02766\n89,16,1.28585,2.05816\n89,17,1.25949,2.0891\n89,18,1.23299,2.12046\n89,19,1.20638,2.15221\n89,20,1.17967,2.18434\n89,21,1.15289,2.21683\n90,2,1.63454,1.67942\n90,3,1.6119,1.70262\n90,4,1.58893,1.72642\n90,5,1.56564,1.75082\n90,6,1.54202,1.7758\n90,7,1.51812,1.80135\n90,8,1.49393,1.82745\n90,9,1.46947,1.85411\n90,10,1.44476,1.88129\n90,11,1.41982,1.909\n90,12,1.39464,1.93721\n90,13,1.36926,1.96592\n90,14,1.34368,1.9951\n90,15,1.31792,2.02474\n90,16,1.292,2.05483\n90,17,1.26594,2.08533\n90,18,1.23974,2.11626\n90,19,1.21344,2.14756\n90,20,1.18703,2.17925\n90,21,1.16053,2.21129\n91,2,1.63664,1.68102\n91,3,1.61425,1.70395\n91,4,1.59154,1.72747\n91,5,1.5685,1.75157\n91,6,1.54516,1.77625\n91,7,1.52154,1.80147\n91,8,1.49763,1.82725\n91,9,1.47345,1.85356\n91,10,1.44903,1.8804\n91,11,1.42437,1.90774\n91,12,1.39948,1.93557\n91,13,1.3744,1.96389\n91,14,1.34911,1.99268\n91,15,1.32365,2.02192\n91,16,1.29803,2.05159\n91,17,1.27226,2.08168\n91,18,1.24637,2.11217\n91,19,1.22035,2.14305\n91,20,1.19424,2.1743\n91,21,1.16803,2.2059\n92,2,1.6387,1.68259\n92,3,1.61656,1.70526\n92,4,1.5941,1.72851\n92,5,1.57132,1.75232\n92,6,1.54824,1.7767\n92,7,1.52488,1.80161\n92,8,1.50125,1.82707\n92,9,1.47736,1.85304\n92,10,1.45321,1.87953\n92,11,1.42883,1.90652\n92,12,1.40423,1.93399\n92,13,1.37943,1.96194\n92,14,1.35444,1.99033\n92,15,1.32927,2.01918\n92,16,1.30393,2.04845\n92,17,1.27846,2.07813\n92,18,1.25285,2.10821\n92,19,1.22713,2.13867\n92,20,1.20129,2.16949\n92,21,1.17538,2.20066\n93,2,1.64073,1.68414\n93,3,1.61883,1.70656\n93,4,1.59661,1.72954\n93,5,1.57409,1.75308\n93,6,1.55127,1.77716\n93,7,1.52818,1.80176\n93,8,1.5048,1.8269\n93,9,1.48117,1.85255\n93,10,1.4573,1.8787\n93,11,1.43321,1.90534\n93,12,1.40889,1.93246\n93,13,1.38437,1.96004\n93,14,1.35966,1.98806\n93,15,1.33477,2.01652\n93,16,1.30972,2.0454\n93,17,1.28453,2.07469\n93,18,1.2592,2.10436\n93,19,1.23376,2.13441\n93,20,1.20821,2.16482\n93,21,1.18259,2.19556\n94,2,1.64272,1.68567\n94,3,1.62106,1.70784\n94,4,1.59908,1.73055\n94,5,1.57681,1.75382\n94,6,1.55424,1.77761\n94,7,1.5314,1.80192\n94,8,1.50829,1.82675\n94,9,1.48493,1.85209\n94,10,1.46133,1.87791\n94,11,1.4375,1.90421\n94,12,1.41345,1.93097\n94,13,1.38921,1.9582\n94,14,1.36478,1.98586\n94,15,1.34016,2.01394\n94,16,1.3154,2.04244\n94,17,1.29049,2.07134\n94,18,1.26544,2.10062\n94,19,1.24027,2.13027\n94,20,1.215,2.16027\n94,21,1.18965,2.19061\n95,2,1.64469,1.68717\n95,3,1.62325,1.7091\n95,4,1.60152,1.73156\n95,5,1.57948,1.75455\n95,6,1.55715,1.77807\n95,7,1.53456,1.8021\n95,8,1.51171,1.82663\n95,9,1.48861,1.85164\n95,10,1.46527,1.87715\n95,11,1.44171,1.90311\n95,12,1.41793,1.92954\n95,13,1.39395,1.95642\n95,14,1.3698,1.98372\n95,15,1.34546,2.01144\n95,16,1.32096,2.03957\n95,17,1.29632,2.06808\n95,18,1.27155,2.09699\n95,19,1.24666,2.12624\n95,20,1.22166,2.15585\n95,21,1.19657,2.18579\n96,2,1.64661,1.68866\n96,3,1.62541,1.71034\n96,4,1.6039,1.73256\n96,5,1.58211,1.75529\n96,6,1.56002,1.77853\n96,7,1.53768,1.80227\n96,8,1.51508,1.82651\n96,9,1.49223,1.85123\n96,10,1.46914,1.87642\n96,11,1.44584,1.90206\n96,12,1.42232,1.92815\n96,13,1.39861,1.95469\n96,14,1.37472,1.98164\n96,15,1.35065,2.009\n96,16,1.32643,2.03677\n96,17,1.30205,2.06492\n96,18,1.27755,2.09345\n96,19,1.25292,2.12232\n96,20,1.22819,2.15154\n96,21,1.20337,2.18109\n97,2,1.64851,1.69012\n97,3,1.62752,1.71157\n97,4,1.60625,1.73354\n97,5,1.58469,1.75602\n97,6,1.56284,1.77899\n97,7,1.54073,1.80246\n97,8,1.51838,1.82641\n97,9,1.49577,1.85083\n97,10,1.47294,1.87571\n97,11,1.44989,1.90105\n97,12,1.42663,1.92681\n97,13,1.40318,1.95301\n97,14,1.37955,1.97963\n97,15,1.35574,2.00665\n97,16,1.33178,2.03407\n97,17,1.30767,2.06186\n97,18,1.28342,2.09001\n97,19,1.25906,2.11851\n97,20,1.23459,2.14735\n97,21,1.21003,2.17652\n98,2,1.65038,1.69156\n98,3,1.62962,1.71279\n98,4,1.60856,1.73452\n98,5,1.58721,1.75674\n98,6,1.56561,1.77946\n98,7,1.54373,1.80266\n98,8,1.52162,1.82632\n98,9,1.49926,1.85046\n98,10,1.47667,1.87503\n98,11,1.45387,1.90006\n98,12,1.43087,1.92552\n98,13,1.40767,1.95139\n98,14,1.38428,1.97768\n98,15,1.36073,2.00436\n98,16,1.33702,2.03142\n98,17,1.31318,2.05886\n98,18,1.28919,2.08666\n98,19,1.26508,2.11481\n98,20,1.24088,2.14328\n98,21,1.21657,2.17208\n99,2,1.65223,1.69298\n99,3,1.63167,1.71399\n99,4,1.61082,1.73548\n99,5,1.58971,1.75746\n99,6,1.56833,1.77993\n99,7,1.54669,1.80285\n99,8,1.5248,1.82625\n99,9,1.50268,1.8501\n99,10,1.48033,1.87439\n99,11,1.45778,1.89911\n99,12,1.43502,1.92426\n99,13,1.41206,1.94982\n99,14,1.38894,1.97578\n99,15,1.36563,2.00213\n99,16,1.34218,2.02886\n99,17,1.31859,2.05596\n99,18,1.29486,2.08341\n99,19,1.271,2.1112\n99,20,1.24704,2.13931\n99,21,1.22298,2.16774\n100,2,1.65404,1.69439\n100,3,1.63369,1.71517\n100,4,1.61306,1.73643\n100,5,1.59216,1.75818\n100,6,1.571,1.78039\n100,7,1.54958,1.80306\n100,8,1.52793,1.82619\n100,9,1.50604,1.84976\n100,10,1.48394,1.87377\n100,11,1.46162,1.8982\n100,12,1.4391,1.92305\n100,13,1.41639,1.9483\n100,14,1.3935,1.97394\n100,15,1.37045,1.99997\n100,16,1.34724,2.02636\n100,17,1.3239,2.05313\n100,18,1.30041,2.08024\n100,19,1.2768,2.10767\n100,20,1.2531,2.13544\n100,21,1.22928,2.16352\n101,2,1.65582,1.69577\n101,3,1.63568,1.71634\n101,4,1.61526,1.73738\n101,5,1.59457,1.75888\n101,6,1.57363,1.78086\n101,7,1.55244,1.80328\n101,8,1.531,1.82614\n101,9,1.50934,1.84945\n101,10,1.48747,1.87317\n101,11,1.46538,1.89731\n101,12,1.4431,1.92186\n101,13,1.42063,1.94682\n101,14,1.39799,1.97215\n101,15,1.37518,1.99787\n101,16,1.35221,2.02394\n101,17,1.32911,2.05037\n101,18,1.30587,2.07715\n101,19,1.2825,2.10425\n101,20,1.25903,2.13168\n101,21,1.23546,2.15941\n102,2,1.65758,1.69713\n102,3,1.63764,1.71749\n102,4,1.61742,1.73831\n102,5,1.59694,1.75959\n102,6,1.57621,1.78132\n102,7,1.55524,1.80349\n102,8,1.53403,1.8261\n102,9,1.5126,1.84914\n102,10,1.49094,1.87259\n102,11,1.46909,1.89646\n102,12,1.44704,1.92072\n102,13,1.4248,1.94538\n102,14,1.40239,1.97042\n102,15,1.37982,1.99582\n102,16,1.35709,2.02159\n102,17,1.33422,2.04769\n102,18,1.31122,2.07414\n102,19,1.28809,2.10092\n102,20,1.26486,2.128\n102,21,1.24154,2.1554\n103,2,1.65932,1.69848\n103,3,1.63956,1.71863\n103,4,1.61955,1.73924\n103,5,1.59928,1.76029\n103,6,1.57875,1.78179\n103,7,1.55799,1.80372\n103,8,1.537,1.82608\n103,9,1.51578,1.84886\n103,10,1.49435,1.87205\n103,11,1.47272,1.89563\n103,12,1.4509,1.91962\n103,13,1.42889,1.94398\n103,14,1.40671,1.96873\n103,15,1.38437,1.99383\n103,16,1.36188,2.01929\n103,17,1.33924,2.04509\n103,18,1.31648,2.07122\n103,19,1.29359,2.09767\n103,20,1.27059,2.12443\n103,21,1.2475,2.15149\n104,2,1.66103,1.69981\n104,3,1.64147,1.71976\n104,4,1.62165,1.74015\n104,5,1.60157,1.76098\n104,6,1.58126,1.78226\n104,7,1.5607,1.80395\n104,8,1.53991,1.82607\n104,9,1.51892,1.84859\n104,10,1.4977,1.87152\n104,11,1.47629,1.89484\n104,12,1.45469,1.91855\n104,13,1.43291,1.94263\n104,14,1.41096,1.96709\n104,15,1.38885,1.9919\n104,16,1.36658,2.01706\n104,17,1.34417,2.04255\n104,18,1.32164,2.06836\n104,19,1.29899,2.0945\n104,20,1.27622,2.12095\n104,21,1.25335,2.14768\n105,2,1.66271,1.70111\n105,3,1.64334,1.72087\n105,4,1.62371,1.74106\n105,5,1.60383,1.76168\n105,6,1.58372,1.78273\n105,7,1.56336,1.80419\n105,8,1.54279,1.82606\n105,9,1.522,1.84834\n105,10,1.50101,1.87101\n105,11,1.47981,1.89407\n105,12,1.45843,1.91751\n105,13,1.43687,1.94132\n105,14,1.41514,1.9655\n105,15,1.39325,1.99001\n105,16,1.3712,2.01488\n105,17,1.34903,2.04007\n105,18,1.32672,2.06559\n105,19,1.30428,2.09141\n105,20,1.28174,2.11754\n105,21,1.2591,2.14396\n106,2,1.66436,1.70241\n106,3,1.64518,1.72197\n106,4,1.62575,1.74195\n106,5,1.60606,1.76236\n106,6,1.58613,1.78319\n106,7,1.56599,1.80443\n106,8,1.54562,1.82607\n106,9,1.52503,1.8481\n106,10,1.50425,1.87053\n106,11,1.48326,1.89333\n106,12,1.4621,1.91651\n106,13,1.44075,1.94005\n106,14,1.41924,1.96395\n106,15,1.39756,1.98818\n106,16,1.37575,2.01275\n106,17,1.35378,2.03766\n106,18,1.33169,2.06288\n106,19,1.30949,2.08841\n106,20,1.28717,2.11423\n106,21,1.26475,2.14033\n107,2,1.666,1.70369\n107,3,1.64699,1.72305\n107,4,1.62774,1.74284\n107,5,1.60825,1.76305\n107,6,1.58852,1.78365\n107,7,1.56856,1.80467\n107,8,1.5484,1.82608\n107,9,1.52801,1.84788\n107,10,1.50744,1.87006\n107,11,1.48666,1.89262\n107,12,1.4657,1.91553\n107,13,1.44457,1.93881\n107,14,1.42326,1.96244\n107,15,1.40181,1.9864\n107,16,1.38021,2.0107\n107,17,1.35847,2.03531\n107,18,1.33659,2.06024\n107,19,1.3146,2.08547\n107,20,1.29251,2.11099\n107,21,1.2703,2.13679\n108,2,1.66761,1.70495\n108,3,1.64878,1.72413\n108,4,1.62971,1.74372\n108,5,1.61041,1.76372\n108,6,1.59087,1.78412\n108,7,1.5711,1.80492\n108,8,1.55113,1.82611\n108,9,1.53095,1.84767\n108,10,1.51057,1.86962\n108,11,1.49,1.89192\n108,12,1.46925,1.91459\n108,13,1.44832,1.93761\n108,14,1.42723,1.96097\n108,15,1.40598,1.98466\n108,16,1.3846,2.00868\n108,17,1.36307,2.03302\n108,18,1.34141,2.05766\n108,19,1.31963,2.0826\n108,20,1.29775,2.10783\n108,21,1.27576,2.13334\n109,2,1.6692,1.70619\n109,3,1.65054,1.72519\n109,4,1.63165,1.74459\n109,5,1.61253,1.76439\n109,6,1.59317,1.78459\n109,7,1.57361,1.80518\n109,8,1.55382,1.82614\n109,9,1.53384,1.84749\n109,10,1.51365,1.86919\n109,11,1.49329,1.89126\n109,12,1.47274,1.91368\n109,13,1.45201,1.93644\n109,14,1.43113,1.95954\n109,15,1.41009,1.98298\n109,16,1.38891,2.00672\n109,17,1.36758,2.03079\n109,18,1.34614,2.05515\n109,19,1.32457,2.07981\n109,20,1.3029,2.10475\n109,21,1.28112,2.12997\n110,2,1.67076,1.70741\n110,3,1.65228,1.72623\n110,4,1.63357,1.74545\n110,5,1.61462,1.76506\n110,6,1.59545,1.78506\n110,7,1.57606,1.80543\n110,8,1.55647,1.82618\n110,9,1.53667,1.8473\n110,10,1.51668,1.86878\n110,11,1.49651,1.89061\n110,12,1.47617,1.91279\n110,13,1.45564,1.93531\n110,14,1.43496,1.95815\n110,15,1.41412,1.98133\n110,16,1.39315,2.00481\n110,17,1.37203,2.02861\n110,18,1.35079,2.0527\n110,19,1.32943,2.07709\n110,20,1.30796,2.10175\n110,21,1.28639,2.12668\n111,2,1.67231,1.70863\n111,3,1.65399,1.72727\n111,4,1.63545,1.7463\n111,5,1.61668,1.76572\n111,6,1.59769,1.78552\n111,7,1.57848,1.80569\n111,8,1.55908,1.82623\n111,9,1.53947,1.84713\n111,10,1.51967,1.86838\n111,11,1.49969,1.88999\n111,12,1.47954,1.91193\n111,13,1.45921,1.93421\n111,14,1.43873,1.9568\n111,15,1.4181,1.97972\n111,16,1.39732,2.00296\n111,17,1.37641,2.02649\n111,18,1.35536,2.05032\n111,19,1.33421,2.07443\n111,20,1.31294,2.09881\n111,21,1.29157,2.12346\n112,2,1.67383,1.70982\n112,3,1.65568,1.7283\n112,4,1.63731,1.74715\n112,5,1.61871,1.76637\n112,6,1.5999,1.78598\n112,7,1.58087,1.80596\n112,8,1.56164,1.82628\n112,9,1.54222,1.84697\n112,10,1.52261,1.868\n112,11,1.50282,1.88939\n112,12,1.48285,1.91109\n112,13,1.46272,1.93313\n112,14,1.44244,1.9555\n112,15,1.42199,1.97817\n112,16,1.40142,2.00114\n112,17,1.3807,2.02442\n112,18,1.35986,2.04798\n112,19,1.3389,2.07182\n112,20,1.31784,2.09594\n112,21,1.29666,2.12032\n113,2,1.67533,1.71101\n113,3,1.65735,1.72931\n113,4,1.63914,1.74798\n113,5,1.62071,1.76703\n113,6,1.60206,1.78644\n113,7,1.58322,1.80622\n113,8,1.56417,1.82635\n113,9,1.54492,1.84682\n113,10,1.5255,1.86764\n113,11,1.5059,1.88879\n113,12,1.48612,1.91029\n113,13,1.46618,1.93209\n113,14,1.44608,1.95421\n113,15,1.42584,1.97664\n113,16,1.40545,1.99938\n113,17,1.38493,2.02239\n113,18,1.36428,2.0457\n113,19,1.34352,2.06929\n113,20,1.32265,2.09314\n113,21,1.30168,2.11725\n114,2,1.67681,1.71217\n114,3,1.65899,1.73031\n114,4,1.64095,1.74881\n114,5,1.62268,1.76768\n114,6,1.60421,1.78691\n114,7,1.58554,1.80649\n114,8,1.56666,1.82642\n114,9,1.5476,1.84669\n114,10,1.52835,1.8673\n114,11,1.50892,1.88824\n114,12,1.48933,1.9095\n114,13,1.46958,1.93108\n114,14,1.44967,1.95297\n114,15,1.42962,1.97516\n114,16,1.40942,1.99765\n114,17,1.38909,2.02042\n114,18,1.36864,2.04348\n114,19,1.34806,2.06681\n114,20,1.32739,2.0904\n114,21,1.30661,2.11426\n115,2,1.67828,1.71333\n115,3,1.66061,1.73129\n115,4,1.64272,1.74963\n115,5,1.62462,1.76832\n115,6,1.60632,1.78737\n115,7,1.58781,1.80676\n115,8,1.56911,1.8265\n115,9,1.55022,1.84656\n115,10,1.53115,1.86697\n115,11,1.5119,1.88769\n115,12,1.4925,1.90873\n115,13,1.47293,1.93009\n115,14,1.4532,1.95176\n115,15,1.43333,1.97372\n115,16,1.41332,1.99597\n115,17,1.39318,2.0185\n115,18,1.37291,2.04131\n115,19,1.35254,2.06439\n115,20,1.33205,2.08773\n115,21,1.31146,2.11133\n116,2,1.67972,1.71446\n116,3,1.66221,1.73228\n116,4,1.64448,1.75044\n116,5,1.62654,1.76896\n116,6,1.60839,1.78782\n116,7,1.59005,1.80703\n116,8,1.57152,1.82658\n116,9,1.5528,1.84645\n116,10,1.53391,1.86665\n116,11,1.51484,1.88716\n116,12,1.49561,1.90799\n116,13,1.47621,1.92914\n116,14,1.45668,1.95058\n116,15,1.43699,1.97231\n116,16,1.41716,1.99432\n116,17,1.39721,2.01662\n116,18,1.37713,2.03919\n116,19,1.35693,2.06203\n116,20,1.33663,2.08512\n116,21,1.31624,2.10846\n117,2,1.68115,1.71559\n117,3,1.66378,1.73324\n117,4,1.64621,1.75124\n117,5,1.62843,1.7696\n117,6,1.61045,1.78828\n117,7,1.59227,1.80731\n117,8,1.5739,1.82666\n117,9,1.55535,1.84634\n117,10,1.53663,1.86634\n117,11,1.51774,1.88666\n117,12,1.49868,1.90728\n117,13,1.47946,1.9282\n117,14,1.46009,1.94943\n117,15,1.44059,1.97093\n117,16,1.42094,1.99272\n117,17,1.40116,2.01478\n117,18,1.38128,2.03712\n117,19,1.36126,2.05971\n117,20,1.34114,2.08257\n117,21,1.32093,2.10566\n118,2,1.68255,1.7167\n118,3,1.66534,1.7342\n118,4,1.64792,1.75204\n118,5,1.63029,1.77022\n118,6,1.61246,1.78873\n118,7,1.59445,1.80759\n118,8,1.57625,1.82675\n118,9,1.55787,1.84625\n118,10,1.53931,1.86605\n118,11,1.52058,1.88616\n118,12,1.50169,1.90659\n118,13,1.48265,1.92729\n118,14,1.46347,1.9483\n118,15,1.44413,1.96959\n118,16,1.42467,1.99116\n118,17,1.40507,2.013\n118,18,1.38535,2.0351\n118,19,1.36552,2.05746\n118,20,1.34558,2.08007\n118,21,1.32555,2.10293\n119,2,1.68394,1.7178\n119,3,1.66687,1.73515\n119,4,1.6496,1.75283\n119,5,1.63212,1.77085\n119,6,1.61446,1.78919\n119,7,1.5966,1.80786\n119,8,1.57855,1.82686\n119,9,1.56033,1.84616\n119,10,1.54195,1.86577\n119,11,1.52338,1.88569\n119,12,1.50466,1.90591\n119,13,1.48579,1.92641\n119,14,1.46678,1.94721\n119,15,1.44762,1.96828\n119,16,1.42832,1.98963\n119,17,1.4089,2.01124\n119,18,1.38936,2.03312\n119,19,1.36972,2.05525\n119,20,1.34995,2.07763\n119,21,1.33009,2.10024\n120,2,1.68531,1.71889\n120,3,1.66839,1.73608\n120,4,1.65126,1.75361\n120,5,1.63394,1.77146\n120,6,1.61642,1.78964\n120,7,1.59872,1.80815\n120,8,1.58083,1.82696\n120,9,1.56276,1.84608\n120,10,1.54454,1.86551\n120,11,1.52615,1.88523\n120,12,1.50759,1.90525\n120,13,1.48889,1.92556\n120,14,1.47004,1.94614\n120,15,1.45106,1.96701\n120,16,1.43193,1.98814\n120,17,1.41269,2.00954\n120,18,1.39332,2.03119\n120,19,1.37385,2.0531\n120,20,1.35425,2.07524\n120,21,1.33457,2.09762\n121,2,1.68666,1.71996\n121,3,1.66988,1.73701\n121,4,1.6529,1.75438\n121,5,1.63572,1.77209\n121,6,1.61835,1.7901\n121,7,1.6008,1.80843\n121,8,1.58307,1.82706\n121,9,1.56517,1.84601\n121,10,1.5471,1.86525\n121,11,1.52886,1.88479\n121,12,1.51047,1.90461\n121,13,1.49194,1.92471\n121,14,1.47325,1.9451\n121,15,1.45443,1.96576\n121,16,1.43549,1.98668\n121,17,1.41641,2.00787\n121,18,1.39721,2.0293\n121,19,1.37791,2.05099\n121,20,1.35849,2.07291\n121,21,1.33898,2.09507\n122,2,1.688,1.72102\n122,3,1.67135,1.73792\n122,4,1.65452,1.75515\n122,5,1.63748,1.77269\n122,6,1.62027,1.79054\n122,7,1.60286,1.80871\n122,8,1.58528,1.82718\n122,9,1.56754,1.84594\n122,10,1.54962,1.865\n122,11,1.53155,1.88436\n122,12,1.51332,1.904\n122,13,1.49495,1.92391\n122,14,1.47642,1.94409\n122,15,1.45777,1.96455\n122,16,1.43899,1.98526\n122,17,1.42007,2.00624\n122,18,1.40104,2.02746\n122,19,1.3819,2.04892\n122,20,1.36266,2.07063\n122,21,1.34332,2.09256\n123,2,1.68932,1.72207\n123,3,1.67281,1.73883\n123,4,1.65611,1.75591\n123,5,1.63922,1.7733\n123,6,1.62215,1.791\n123,7,1.60489,1.80899\n123,8,1.58746,1.8273\n123,9,1.56986,1.84589\n123,10,1.5521,1.86478\n123,11,1.53419,1.88394\n123,12,1.51612,1.90339\n123,13,1.4979,1.92311\n123,14,1.47954,1.94311\n123,15,1.46105,1.96336\n123,16,1.44243,1.98388\n123,17,1.42368,2.00464\n123,18,1.40482,2.02566\n123,19,1.38584,2.0469\n123,20,1.36677,2.06839\n123,21,1.34759,2.0901\n124,2,1.69062,1.7231\n124,3,1.67425,1.73973\n124,4,1.65768,1.75666\n124,5,1.64094,1.7739\n124,6,1.624,1.79144\n124,7,1.6069,1.80928\n124,8,1.58961,1.82742\n124,9,1.57216,1.84584\n124,10,1.55456,1.86455\n124,11,1.5368,1.88354\n124,12,1.51888,1.90281\n124,13,1.50081,1.92234\n124,14,1.48261,1.94215\n124,15,1.46428,1.96221\n124,16,1.44582,1.98252\n124,17,1.42724,2.00308\n124,18,1.40854,2.02388\n124,19,1.38973,2.04493\n124,20,1.37082,2.0662\n124,21,1.3518,2.0877\n125,2,1.69191,1.72413\n125,3,1.67567,1.74061\n125,4,1.65924,1.7574\n125,5,1.64263,1.7745\n125,6,1.62584,1.79189\n125,7,1.60887,1.80958\n125,8,1.59173,1.82755\n125,9,1.57443,1.84581\n125,10,1.55697,1.86435\n125,11,1.53936,1.88316\n125,12,1.5216,1.90225\n125,13,1.50369,1.9216\n125,14,1.48565,1.94121\n125,15,1.46747,1.96108\n125,16,1.44916,1.98119\n125,17,1.43074,2.00156\n125,18,1.4122,2.02216\n125,19,1.39355,2.043\n125,20,1.3748,2.06406\n125,21,1.35595,2.08535\n126,2,1.69318,1.72515\n126,3,1.67707,1.74149\n126,4,1.66078,1.75815\n126,5,1.6443,1.77509\n126,6,1.62764,1.79234\n126,7,1.61081,1.80986\n126,8,1.59383,1.82768\n126,9,1.57667,1.84577\n126,10,1.55936,1.86414\n126,11,1.54189,1.88278\n126,12,1.52428,1.90169\n126,13,1.50652,1.92086\n126,14,1.48863,1.94029\n126,15,1.4706,1.95997\n126,16,1.45246,1.9799\n126,17,1.43419,2.00006\n126,18,1.41581,2.02047\n126,19,1.39732,2.04111\n126,20,1.37872,2.06197\n126,21,1.36003,2.08305\n127,2,1.69443,1.72614\n127,3,1.67845,1.74236\n127,4,1.66229,1.75888\n127,5,1.64595,1.77568\n127,6,1.62943,1.79277\n127,7,1.61273,1.81015\n127,8,1.59588,1.82781\n127,9,1.57888,1.84575\n127,10,1.5617,1.86394\n127,11,1.54438,1.88242\n127,12,1.52692,1.90116\n127,13,1.50931,1.92015\n127,14,1.49157,1.9394\n127,15,1.4737,1.9589\n127,16,1.4557,1.97863\n127,17,1.43759,1.99861\n127,18,1.41936,2.01882\n127,19,1.40103,2.03926\n127,20,1.38259,2.05992\n127,21,1.36406,2.08079\n128,2,1.69568,1.72714\n128,3,1.67982,1.74322\n128,4,1.66379,1.7596\n128,5,1.64758,1.77626\n128,6,1.63119,1.79322\n128,7,1.61464,1.81045\n128,8,1.59792,1.82795\n128,9,1.58105,1.84572\n128,10,1.56402,1.86377\n128,11,1.54684,1.88207\n128,12,1.52952,1.90064\n128,13,1.51206,1.91946\n128,14,1.49447,1.93853\n128,15,1.47675,1.95784\n128,16,1.45891,1.9774\n128,17,1.44094,1.99719\n128,18,1.42287,2.01721\n128,19,1.40468,2.03744\n128,20,1.3864,2.05791\n128,21,1.36802,2.07859\n129,2,1.6969,1.72812\n129,3,1.68117,1.74408\n129,4,1.66526,1.76032\n129,5,1.64917,1.77685\n129,6,1.63293,1.79366\n129,7,1.61651,1.81073\n129,8,1.59992,1.82808\n129,9,1.58319,1.84571\n129,10,1.5663,1.86359\n129,11,1.54927,1.88173\n129,12,1.53209,1.90013\n129,13,1.51478,1.91878\n129,14,1.49733,1.93768\n129,15,1.47975,1.95682\n129,16,1.46206,1.97619\n129,17,1.44424,1.99579\n129,18,1.42632,2.01562\n129,19,1.40829,2.03568\n129,20,1.39015,2.05594\n129,21,1.37192,2.07642\n130,2,1.69811,1.72909\n130,3,1.6825,1.74492\n130,4,1.66672,1.76103\n130,5,1.65076,1.77743\n130,6,1.63464,1.79409\n130,7,1.61836,1.81103\n130,8,1.60191,1.82823\n130,9,1.58531,1.84569\n130,10,1.56856,1.86343\n130,11,1.55166,1.8814\n130,12,1.53462,1.89965\n130,13,1.51745,1.91812\n130,14,1.50015,1.93685\n130,15,1.48272,1.9558\n130,16,1.46516,1.975\n130,17,1.4475,1.99442\n130,18,1.42972,2.01407\n130,19,1.41184,2.03393\n130,20,1.39386,2.05401\n130,21,1.37577,2.0743\n131,2,1.69931,1.73005\n131,3,1.68383,1.74575\n131,4,1.66816,1.76174\n131,5,1.65233,1.778\n131,6,1.63633,1.79452\n131,7,1.62017,1.81132\n131,8,1.60386,1.82838\n131,9,1.5874,1.84569\n131,10,1.57078,1.86327\n131,11,1.55402,1.88109\n131,12,1.53712,1.89917\n131,13,1.52009,1.91748\n131,14,1.50292,1.93604\n131,15,1.48564,1.95483\n131,16,1.46823,1.97384\n131,17,1.45071,1.99309\n131,18,1.43308,2.01255\n131,19,1.41534,2.03224\n131,20,1.3975,2.05212\n131,21,1.37957,2.07222\n132,2,1.70049,1.731\n132,3,1.68512,1.74658\n132,4,1.66958,1.76244\n132,5,1.65388,1.77856\n132,6,1.63801,1.79496\n132,7,1.62197,1.81162\n132,8,1.60579,1.82853\n132,9,1.58945,1.84569\n132,10,1.57297,1.86311\n132,11,1.55635,1.88079\n132,12,1.53958,1.89871\n132,13,1.52269,1.91686\n132,14,1.50566,1.93525\n132,15,1.48852,1.95387\n132,16,1.47126,1.97272\n132,17,1.45387,1.99179\n132,18,1.43639,2.01107\n132,19,1.41879,2.03057\n132,20,1.40109,2.05028\n132,21,1.38331,2.07019\n133,2,1.70166,1.73194\n133,3,1.68641,1.7474\n133,4,1.67099,1.76313\n133,5,1.6554,1.77912\n133,6,1.63965,1.79539\n133,7,1.62375,1.81191\n133,8,1.60769,1.82868\n133,9,1.59149,1.84571\n133,10,1.57513,1.86298\n133,11,1.55864,1.8805\n133,12,1.54202,1.89825\n133,13,1.52526,1.91625\n133,14,1.50837,1.93448\n133,15,1.49136,1.95293\n133,16,1.47424,1.97161\n133,17,1.457,1.99051\n133,18,1.43965,2.00962\n133,19,1.42219,2.02894\n133,20,1.40464,2.04846\n133,21,1.387,2.0682\n134,2,1.70282,1.73286\n134,3,1.68768,1.74821\n134,4,1.67238,1.76382\n134,5,1.65691,1.77969\n134,6,1.64129,1.79581\n134,7,1.62551,1.8122\n134,8,1.60957,1.82883\n134,9,1.5935,1.84572\n134,10,1.57727,1.86285\n134,11,1.56091,1.88021\n134,12,1.54442,1.89782\n134,13,1.52779,1.91565\n134,14,1.51104,1.93372\n134,15,1.49416,1.95201\n134,16,1.47717,1.97053\n134,17,1.46007,1.98925\n134,18,1.44286,2.0082\n134,19,1.42554,2.02734\n134,20,1.40813,2.04669\n134,21,1.39063,2.06623\n135,2,1.70397,1.73379\n135,3,1.68894,1.74902\n135,4,1.67375,1.7645\n135,5,1.6584,1.78024\n135,6,1.6429,1.79624\n135,7,1.62723,1.8125\n135,8,1.61142,1.82899\n135,9,1.59547,1.84573\n135,10,1.57937,1.86272\n135,11,1.56315,1.87994\n135,12,1.54677,1.89739\n135,13,1.53028,1.91507\n135,14,1.51367,1.93299\n135,15,1.49692,1.95112\n135,16,1.48007,1.96947\n135,17,1.4631,1.98803\n135,18,1.44604,2.0068\n135,19,1.42885,2.02577\n135,20,1.41158,2.04495\n135,21,1.39422,2.06432\n136,2,1.7051,1.73469\n136,3,1.69018,1.7498\n136,4,1.67511,1.76517\n136,5,1.65987,1.78079\n136,6,1.64448,1.79667\n136,7,1.62894,1.81279\n136,8,1.61326,1.82915\n136,9,1.59742,1.84576\n136,10,1.58145,1.8626\n136,11,1.56535,1.87968\n136,12,1.54911,1.89698\n136,13,1.53275,1.91451\n136,14,1.51626,1.93227\n136,15,1.49966,1.95024\n136,16,1.48293,1.96843\n136,17,1.46609,1.98683\n136,18,1.44916,2.00543\n136,19,1.43212,2.02425\n136,20,1.41499,2.04325\n136,21,1.39776,2.06244\n137,2,1.70621,1.73559\n137,3,1.69141,1.7506\n137,4,1.67645,1.76585\n137,5,1.66133,1.78134\n137,6,1.64606,1.79709\n137,7,1.63064,1.81308\n137,8,1.61507,1.82932\n137,9,1.59936,1.84578\n137,10,1.58351,1.86249\n137,11,1.56753,1.87942\n137,12,1.55142,1.89658\n137,13,1.53517,1.91396\n137,14,1.51881,1.93156\n137,15,1.50235,1.94938\n137,16,1.48575,1.96741\n137,17,1.46905,1.98565\n137,18,1.45225,2.0041\n137,19,1.43534,2.02274\n137,20,1.41833,2.04157\n137,21,1.40124,2.0606\n138,2,1.70732,1.73649\n138,3,1.69262,1.75138\n138,4,1.67777,1.76651\n138,5,1.66277,1.78189\n138,6,1.64761,1.79751\n138,7,1.6323,1.81338\n138,8,1.61685,1.82948\n138,9,1.60126,1.84582\n138,10,1.58554,1.86239\n138,11,1.56968,1.87918\n138,12,1.55369,1.89619\n138,13,1.53758,1.91342\n138,14,1.52134,1.93088\n138,15,1.50499,1.94855\n138,16,1.48853,1.96643\n138,17,1.47196,1.98451\n138,18,1.45529,2.00278\n138,19,1.43852,2.02126\n138,20,1.42164,2.03993\n138,21,1.40469,2.05879\n139,2,1.70841,1.73737\n139,3,1.69383,1.75214\n139,4,1.67908,1.76716\n139,5,1.66418,1.78243\n139,6,1.64914,1.79793\n139,7,1.63395,1.81367\n139,8,1.61861,1.82965\n139,9,1.60314,1.84585\n139,10,1.58754,1.86228\n139,11,1.5718,1.87893\n139,12,1.55593,1.89581\n139,13,1.53995,1.91291\n139,14,1.52383,1.93022\n139,15,1.50761,1.94773\n139,16,1.49128,1.96545\n139,17,1.47483,1.98337\n139,18,1.45829,2.0015\n139,19,1.44164,2.01981\n139,20,1.42491,2.03832\n139,21,1.40807,2.05701\n140,2,1.7095,1.73824\n140,3,1.69501,1.75291\n140,4,1.68038,1.76782\n140,5,1.66559,1.78297\n140,6,1.65066,1.79836\n140,7,1.63557,1.81397\n140,8,1.62036,1.82981\n140,9,1.605,1.84589\n140,10,1.58951,1.86219\n140,11,1.57389,1.87871\n140,12,1.55815,1.89545\n140,13,1.54228,1.9124\n140,14,1.52629,1.92956\n140,15,1.5102,1.94693\n140,16,1.49399,1.96449\n140,17,1.47767,1.98227\n140,18,1.46125,2.00024\n140,19,1.44473,2.0184\n140,20,1.42813,2.03675\n140,21,1.41143,2.05528\n141,2,1.71056,1.7391\n141,3,1.69618,1.75367\n141,4,1.68165,1.76847\n141,5,1.66697,1.7835\n141,6,1.65215,1.79876\n141,7,1.63718,1.81426\n141,8,1.62208,1.82999\n141,9,1.60684,1.84593\n141,10,1.59147,1.86211\n141,11,1.57596,1.87848\n141,12,1.56033,1.89508\n141,13,1.54459,1.9119\n141,14,1.52872,1.92892\n141,15,1.51275,1.94614\n141,16,1.49666,1.96357\n141,17,1.48047,1.98119\n141,18,1.46417,1.999\n141,19,1.44779,2.01701\n141,20,1.4313,2.03519\n141,21,1.41472,2.05357\n142,2,1.71162,1.73997\n142,3,1.69735,1.75442\n142,4,1.68292,1.76911\n142,5,1.66835,1.78403\n142,6,1.65362,1.79918\n142,7,1.63877,1.81456\n142,8,1.62377,1.83016\n142,9,1.60865,1.84598\n142,10,1.59339,1.86202\n142,11,1.578,1.87828\n142,12,1.5625,1.89474\n142,13,1.54686,1.91142\n142,14,1.53112,1.9283\n142,15,1.51527,1.94538\n142,16,1.4993,1.96266\n142,17,1.48323,1.98013\n142,18,1.46706,1.9978\n142,19,1.45079,2.01564\n142,20,1.43444,2.03368\n142,21,1.41799,2.0519\n143,2,1.71267,1.74081\n143,3,1.69849,1.75517\n143,4,1.68417,1.76974\n143,5,1.6697,1.78456\n143,6,1.65509,1.79959\n143,7,1.64034,1.81486\n143,8,1.62546,1.83034\n143,9,1.61043,1.84603\n143,10,1.59529,1.86194\n143,11,1.58002,1.87807\n143,12,1.56463,1.8944\n143,13,1.54912,1.91095\n143,14,1.53348,1.92769\n143,15,1.51776,1.94463\n143,16,1.50191,1.96176\n143,17,1.48595,1.97909\n143,18,1.46991,1.99661\n143,19,1.45376,2.01431\n143,20,1.43753,2.03219\n143,21,1.4212,2.05025\n144,2,1.7137,1.74165\n144,3,1.69963,1.7559\n144,4,1.68541,1.77037\n144,5,1.67104,1.78508\n144,6,1.65653,1.8\n144,7,1.64189,1.81514\n144,8,1.62711,1.83051\n144,9,1.6122,1.84609\n144,10,1.59717,1.86188\n144,11,1.58201,1.87787\n144,12,1.56673,1.89408\n144,13,1.55133,1.91048\n144,14,1.53583,1.92709\n144,15,1.52021,1.94389\n144,16,1.50448,1.96089\n144,17,1.48865,1.97808\n144,18,1.47272,1.99544\n144,19,1.4567,2.01299\n144,20,1.44058,2.03073\n144,21,1.42438,2.04864\n145,2,1.71473,1.74247\n145,3,1.70075,1.75663\n145,4,1.68663,1.771\n145,5,1.67236,1.78559\n145,6,1.65796,1.8004\n145,7,1.64343,1.81544\n145,8,1.62875,1.83069\n145,9,1.61395,1.84615\n145,10,1.59902,1.86181\n145,11,1.58398,1.87768\n145,12,1.56881,1.89375\n145,13,1.55352,1.91003\n145,14,1.53813,1.92651\n145,15,1.52263,1.94317\n145,16,1.50702,1.96003\n145,17,1.49131,1.97707\n145,18,1.4755,1.9943\n145,19,1.45959,2.01171\n145,20,1.44359,2.02929\n145,21,1.42751,2.04706\n146,2,1.71574,1.7433\n146,3,1.70186,1.75735\n146,4,1.68784,1.77162\n146,5,1.67368,1.7861\n146,6,1.65938,1.80082\n146,7,1.64494,1.81574\n146,8,1.63038,1.83087\n146,9,1.61568,1.84621\n146,10,1.60086,1.86175\n146,11,1.58592,1.8775\n146,12,1.57087,1.89345\n146,13,1.55569,1.90959\n146,14,1.54041,1.92594\n146,15,1.52502,1.94247\n146,16,1.50953,1.95919\n146,17,1.49393,1.9761\n146,18,1.47823,1.99319\n146,19,1.46245,2.01045\n146,20,1.44656,2.02789\n146,21,1.4306,2.0455\n147,2,1.71674,1.74412\n147,3,1.70296,1.75807\n147,4,1.68903,1.77224\n147,5,1.67497,1.78662\n147,6,1.66077,1.80121\n147,7,1.64644,1.81603\n147,8,1.63197,1.83104\n147,9,1.61739,1.84627\n147,10,1.60267,1.8617\n147,11,1.58784,1.87732\n147,12,1.5729,1.89315\n147,13,1.55783,1.90916\n147,14,1.54266,1.92538\n147,15,1.52738,1.94178\n147,16,1.51199,1.95837\n147,17,1.49652,1.97514\n147,18,1.48093,1.99209\n147,19,1.46526,2.00921\n147,20,1.4495,2.02651\n147,21,1.43365,2.04397\n148,2,1.71773,1.74493\n148,3,1.70405,1.75878\n148,4,1.69021,1.77285\n148,5,1.67624,1.78713\n148,6,1.66215,1.80162\n148,7,1.64791,1.81632\n148,8,1.63355,1.83123\n148,9,1.61907,1.84634\n148,10,1.60446,1.86165\n148,11,1.58974,1.87716\n148,12,1.5749,1.89286\n148,13,1.55995,1.90875\n148,14,1.54488,1.92484\n148,15,1.52971,1.9411\n148,16,1.51444,1.95756\n148,17,1.49908,1.9742\n148,18,1.4836,1.99101\n148,19,1.46805,2.008\n148,20,1.4524,2.02515\n148,21,1.43666,2.04247\n149,2,1.71873,1.74572\n149,3,1.70512,1.75948\n149,4,1.69139,1.77345\n149,5,1.67752,1.78763\n149,6,1.66351,1.80202\n149,7,1.64938,1.81661\n149,8,1.63512,1.83141\n149,9,1.62074,1.84641\n149,10,1.60623,1.8616\n149,11,1.59161,1.87699\n149,12,1.57688,1.89257\n149,13,1.56204,1.90834\n149,14,1.54708,1.9243\n149,15,1.53202,1.94044\n149,16,1.51686,1.95677\n149,17,1.5016,1.97327\n149,18,1.48624,1.98995\n149,19,1.4708,2.0068\n149,20,1.45526,2.02382\n149,21,1.43964,2.041\n150,2,1.7197,1.74652\n150,3,1.70619,1.76018\n150,4,1.69255,1.77406\n150,5,1.67877,1.78814\n150,6,1.66486,1.80242\n150,7,1.65082,1.8169\n150,8,1.63666,1.83159\n150,9,1.62238,1.84648\n150,10,1.60799,1.86156\n150,11,1.59346,1.87684\n150,12,1.57883,1.89229\n150,13,1.56409,1.90795\n150,14,1.54925,1.92378\n150,15,1.5343,1.9398\n150,16,1.51925,1.956\n150,17,1.5041,1.97237\n150,18,1.48885,1.98891\n150,19,1.47352,2.00563\n150,20,1.45809,2.02251\n150,21,1.44259,2.03955\n151,2,1.72066,1.7473\n151,3,1.70724,1.76087\n151,4,1.69368,1.77465\n151,5,1.68,1.78863\n151,6,1.66619,1.80282\n151,7,1.65225,1.8172\n151,8,1.63819,1.83178\n151,9,1.62401,1.84655\n151,10,1.60971,1.86152\n151,11,1.59529,1.87668\n151,12,1.58077,1.89203\n151,13,1.56613,1.90756\n151,14,1.55139,1.92328\n151,15,1.53654,1.93917\n151,16,1.5216,1.95524\n151,17,1.50656,1.97149\n151,18,1.49142,1.9879\n151,19,1.47619,2.00448\n151,20,1.46088,2.02123\n151,21,1.44549,2.03814\n152,2,1.72161,1.74807\n152,3,1.70828,1.76156\n152,4,1.69482,1.77524\n152,5,1.68123,1.78912\n152,6,1.66751,1.80321\n152,7,1.65367,1.81749\n152,8,1.63971,1.83196\n152,9,1.62562,1.84663\n152,10,1.61142,1.86149\n152,11,1.5971,1.87654\n152,12,1.58267,1.89177\n152,13,1.56815,1.90719\n152,14,1.55351,1.92278\n152,15,1.53877,1.93855\n152,16,1.52393,1.95449\n152,17,1.50898,1.97061\n152,18,1.49396,1.9869\n152,19,1.47884,2.00335\n152,20,1.46364,2.01997\n152,21,1.44835,2.03674\n153,2,1.72256,1.74884\n153,3,1.70931,1.76223\n153,4,1.69594,1.77582\n153,5,1.68244,1.78962\n153,6,1.66881,1.80359\n153,7,1.65507,1.81778\n153,8,1.6412,1.83215\n153,9,1.62721,1.84671\n153,10,1.6131,1.86146\n153,11,1.59889,1.87639\n153,12,1.58457,1.89152\n153,13,1.57014,1.90681\n153,14,1.5556,1.92229\n153,15,1.54095,1.93794\n153,16,1.52622,1.95377\n153,17,1.51139,1.96976\n153,18,1.49647,1.98592\n153,19,1.48146,2.00224\n153,20,1.46636,2.01873\n153,21,1.45118,2.03537\n154,2,1.72349,1.74961\n154,3,1.71034,1.76291\n154,4,1.69706,1.77641\n154,5,1.68364,1.7901\n154,6,1.67011,1.80399\n154,7,1.65645,1.81807\n154,8,1.64267,1.83233\n154,9,1.62878,1.8468\n154,10,1.61478,1.86144\n154,11,1.60066,1.87627\n154,12,1.58643,1.89127\n154,13,1.5721,1.90645\n154,14,1.55766,1.92182\n154,15,1.54313,1.93735\n154,16,1.5285,1.95305\n154,17,1.51377,1.96892\n154,18,1.49895,1.98496\n154,19,1.48405,2.00116\n154,20,1.46905,2.01751\n154,21,1.45398,2.03402\n155,2,1.72442,1.75036\n155,3,1.71135,1.76358\n155,4,1.69815,1.77698\n155,5,1.68483,1.79058\n155,6,1.67139,1.80437\n155,7,1.65782,1.81836\n155,8,1.64413,1.83253\n155,9,1.63034,1.84688\n155,10,1.61643,1.86142\n155,11,1.60241,1.87613\n155,12,1.58827,1.89103\n155,13,1.57404,1.9061\n155,14,1.55971,1.92135\n155,15,1.54527,1.93677\n155,16,1.53074,1.95235\n155,17,1.51612,1.9681\n155,18,1.50139,1.98402\n155,19,1.48659,2.00009\n155,20,1.47171,2.01631\n155,21,1.45674,2.0327\n156,2,1.72532,1.75111\n156,3,1.71234,1.76423\n156,4,1.69924,1.77755\n156,5,1.686,1.79107\n156,6,1.67265,1.80477\n156,7,1.65917,1.81864\n156,8,1.64558,1.83271\n156,9,1.63188,1.84697\n156,10,1.61806,1.8614\n156,11,1.60413,1.87602\n156,12,1.5901,1.8908\n156,13,1.57596,1.90576\n156,14,1.56172,1.9209\n156,15,1.54739,1.9362\n156,16,1.53296,1.95166\n156,17,1.51843,1.9673\n156,18,1.50382,1.98309\n156,19,1.48912,1.99903\n156,20,1.47434,2.01514\n156,21,1.45946,2.0314\n157,2,1.72623,1.75185\n157,3,1.71333,1.76489\n157,4,1.70032,1.77812\n157,5,1.68716,1.79154\n157,6,1.6739,1.80515\n157,7,1.66051,1.81894\n157,8,1.64701,1.8329\n157,9,1.6334,1.84706\n157,10,1.61968,1.86139\n157,11,1.60584,1.87589\n157,12,1.59191,1.89058\n157,13,1.57786,1.90543\n157,14,1.56372,1.92045\n157,15,1.54949,1.93564\n157,16,1.53515,1.951\n157,17,1.52073,1.9665\n157,18,1.50621,1.98218\n157,19,1.49161,1.99801\n157,20,1.47693,2.01399\n157,21,1.46217,2.03012\n158,2,1.72713,1.7526\n158,3,1.71432,1.76555\n158,4,1.70137,1.77868\n158,5,1.68832,1.79202\n158,6,1.67514,1.80552\n158,7,1.66184,1.81922\n158,8,1.64842,1.8331\n158,9,1.6349,1.84715\n158,10,1.62127,1.86138\n158,11,1.60752,1.87578\n158,12,1.59369,1.89036\n158,13,1.57973,1.9051\n158,14,1.56569,1.92002\n158,15,1.55155,1.9351\n158,16,1.53732,1.95033\n158,17,1.52299,1.96572\n158,18,1.50857,1.98128\n158,19,1.49407,1.99699\n158,20,1.47949,2.01285\n158,21,1.46483,2.02886\n159,2,1.72802,1.75332\n159,3,1.71529,1.76619\n159,4,1.70243,1.77924\n159,5,1.68946,1.79249\n159,6,1.67636,1.80591\n159,7,1.66314,1.81951\n159,8,1.64982,1.83329\n159,9,1.63639,1.84724\n159,10,1.62285,1.86138\n159,11,1.6092,1.87568\n159,12,1.59544,1.89015\n159,13,1.5816,1.90478\n159,14,1.56764,1.91959\n159,15,1.55359,1.93455\n159,16,1.53945,1.94968\n159,17,1.52523,1.96497\n159,18,1.51091,1.9804\n159,19,1.4965,1.996\n159,20,1.48202,2.01174\n159,21,1.46746,2.02763\n160,2,1.7289,1.75405\n160,3,1.71625,1.76683\n160,4,1.70348,1.7798\n160,5,1.69058,1.79296\n160,6,1.67756,1.80629\n160,7,1.66444,1.8198\n160,8,1.65121,1.83348\n160,9,1.63786,1.84734\n160,10,1.62441,1.86138\n160,11,1.61084,1.87558\n160,12,1.59718,1.88994\n160,13,1.58343,1.90448\n160,14,1.56957,1.91918\n160,15,1.55562,1.93403\n160,16,1.54158,1.94904\n160,17,1.52744,1.96422\n160,18,1.51322,1.97954\n160,19,1.49892,1.99502\n160,20,1.48452,2.01064\n160,21,1.47006,2.02642\n161,2,1.72978,1.75475\n161,3,1.7172,1.76747\n161,4,1.7045,1.78035\n161,5,1.69169,1.79342\n161,6,1.67876,1.80666\n161,7,1.66573,1.82009\n161,8,1.65257,1.83368\n161,9,1.63932,1.84744\n161,10,1.62595,1.86138\n161,11,1.61248,1.87548\n161,12,1.59891,1.88974\n161,13,1.58524,1.90417\n161,14,1.57148,1.91877\n161,15,1.55761,1.93352\n161,16,1.54367,1.94842\n161,17,1.52962,1.96349\n161,18,1.5155,1.97869\n161,19,1.50129,1.99406\n161,20,1.487,2.00957\n161,21,1.47263,2.02522\n162,2,1.73064,1.75546\n162,3,1.71815,1.7681\n162,4,1.70553,1.7809\n162,5,1.69279,1.79388\n162,6,1.67995,1.80703\n162,7,1.667,1.82037\n162,8,1.65393,1.83386\n162,9,1.64075,1.84754\n162,10,1.62748,1.86138\n162,11,1.6141,1.87538\n162,12,1.60062,1.88955\n162,13,1.58703,1.90388\n162,14,1.57336,1.91837\n162,15,1.55959,1.93301\n162,16,1.54573,1.94781\n162,17,1.53179,1.96276\n162,18,1.51776,1.97786\n162,19,1.50365,1.99311\n162,20,1.48944,2.00851\n162,21,1.47517,2.02405\n163,2,1.7315,1.75617\n163,3,1.71908,1.76872\n163,4,1.70655,1.78144\n163,5,1.69389,1.79434\n163,6,1.68112,1.80741\n163,7,1.66826,1.82065\n163,8,1.65527,1.83407\n163,9,1.64218,1.84764\n163,10,1.62899,1.86139\n163,11,1.61569,1.8753\n163,12,1.6023,1.88936\n163,13,1.5888,1.90359\n163,14,1.57522,1.91797\n163,15,1.56155,1.93252\n163,16,1.54778,1.94721\n163,17,1.53393,1.96206\n163,18,1.51998,1.97705\n163,19,1.50596,1.99219\n163,20,1.49187,2.00747\n163,21,1.47769,2.02289\n164,2,1.73235,1.75687\n164,3,1.72,1.76934\n164,4,1.70754,1.78198\n164,5,1.69497,1.79479\n164,6,1.68229,1.80778\n164,7,1.66949,1.82093\n164,8,1.65659,1.83426\n164,9,1.64359,1.84775\n164,10,1.63048,1.8614\n164,11,1.61727,1.8752\n164,12,1.60397,1.88918\n164,13,1.59056,1.90331\n164,14,1.57706,1.91759\n164,15,1.56348,1.93204\n164,16,1.5498,1.94662\n164,17,1.53604,1.96136\n164,18,1.52219,1.97624\n164,19,1.50827,1.99127\n164,20,1.49425,2.00644\n164,21,1.48017,2.02175\n165,2,1.73319,1.75756\n165,3,1.72092,1.76995\n165,4,1.70854,1.78251\n165,5,1.69604,1.79525\n165,6,1.68344,1.80815\n165,7,1.67073,1.82122\n165,8,1.65791,1.83445\n165,9,1.64498,1.84785\n165,10,1.63195,1.86141\n165,11,1.61883,1.87513\n165,12,1.60561,1.88901\n165,13,1.5923,1.90303\n165,14,1.57889,1.91722\n165,15,1.56539,1.93155\n165,16,1.5518,1.94604\n165,17,1.53813,1.96068\n165,18,1.52437,1.97546\n165,19,1.51053,1.99037\n165,20,1.49661,2.00544\n165,21,1.48262,2.02063\n166,2,1.73403,1.75824\n166,3,1.72182,1.77056\n166,4,1.70952,1.78305\n166,5,1.6971,1.7957\n166,6,1.68458,1.80852\n166,7,1.67195,1.8215\n166,8,1.65921,1.83464\n166,9,1.64636,1.84796\n166,10,1.63342,1.86142\n166,11,1.62038,1.87505\n166,12,1.60724,1.88883\n166,13,1.59401,1.90277\n166,14,1.58069,1.91686\n166,15,1.56728,1.93109\n166,16,1.55378,1.94547\n166,17,1.54019,1.96001\n166,18,1.52652,1.97468\n166,19,1.51278,1.98949\n166,20,1.49895,2.00445\n166,21,1.48505,2.01954\n167,2,1.73484,1.75892\n167,3,1.72272,1.77116\n167,4,1.71049,1.78357\n167,5,1.69815,1.79614\n167,6,1.68571,1.80888\n167,7,1.67315,1.82178\n167,8,1.66049,1.83484\n167,9,1.64773,1.84806\n167,10,1.63487,1.86145\n167,11,1.62191,1.87498\n167,12,1.60886,1.88867\n167,13,1.59571,1.90251\n167,14,1.58247,1.9165\n167,15,1.56915,1.93064\n167,16,1.55573,1.94492\n167,17,1.54224,1.95935\n167,18,1.52866,1.97391\n167,19,1.515,1.98863\n167,20,1.50126,2.00347\n167,21,1.48745,2.01846\n168,2,1.73566,1.75959\n168,3,1.72362,1.77176\n168,4,1.71146,1.78409\n168,5,1.6992,1.79658\n168,6,1.68682,1.80924\n168,7,1.67434,1.82206\n168,8,1.66176,1.83504\n168,9,1.64908,1.84817\n168,10,1.6363,1.86147\n168,11,1.62342,1.87491\n168,12,1.61045,1.88851\n168,13,1.59739,1.90226\n168,14,1.58423,1.91614\n168,15,1.571,1.93019\n168,16,1.55767,1.94437\n168,17,1.54426,1.9587\n168,18,1.53077,1.97317\n168,19,1.51719,1.98777\n168,20,1.50355,2.00252\n168,21,1.48983,2.01739\n169,2,1.73647,1.76027\n169,3,1.7245,1.77236\n169,4,1.71241,1.78461\n169,5,1.70022,1.79703\n169,6,1.68793,1.8096\n169,7,1.67553,1.82234\n169,8,1.66302,1.83523\n169,9,1.65042,1.84829\n169,10,1.63772,1.86149\n169,11,1.62492,1.87484\n169,12,1.61203,1.88835\n169,13,1.59905,1.902\n169,14,1.58598,1.91581\n169,15,1.57282,1.92975\n169,16,1.55958,1.94383\n169,17,1.54625,1.95806\n169,18,1.53285,1.97244\n169,19,1.51937,1.98694\n169,20,1.5058,2.00158\n169,21,1.49217,2.01635\n170,2,1.73728,1.76093\n170,3,1.72537,1.77295\n170,4,1.71336,1.78512\n170,5,1.70124,1.79747\n170,6,1.68902,1.80997\n170,7,1.67669,1.82262\n170,8,1.66427,1.83543\n170,9,1.65174,1.84839\n170,10,1.63912,1.86151\n170,11,1.62641,1.87478\n170,12,1.61359,1.8882\n170,13,1.60069,1.90176\n170,14,1.5877,1.91546\n170,15,1.57464,1.92932\n170,16,1.56147,1.94331\n170,17,1.54823,1.95744\n170,18,1.53491,1.97171\n170,19,1.52151,1.98612\n170,20,1.50803,2.00065\n170,21,1.49449,2.01531\n171,2,1.73808,1.76159\n171,3,1.72624,1.77353\n171,4,1.7143,1.78564\n171,5,1.70225,1.7979\n171,6,1.6901,1.81032\n171,7,1.67785,1.8229\n171,8,1.6655,1.83563\n171,9,1.65305,1.84851\n171,10,1.64051,1.86154\n171,11,1.62788,1.87473\n171,12,1.61514,1.88805\n171,13,1.60233,1.90152\n171,14,1.58941,1.91514\n171,15,1.57642,1.9289\n171,16,1.56335,1.94279\n171,17,1.55019,1.95683\n171,18,1.53695,1.971\n171,19,1.52363,1.98531\n171,20,1.51024,1.99974\n171,21,1.49679,2.01431\n172,2,1.73887,1.76223\n172,3,1.7271,1.77411\n172,4,1.71523,1.78614\n172,5,1.70325,1.79833\n172,6,1.69118,1.81067\n172,7,1.679,1.82318\n172,8,1.66672,1.83582\n172,9,1.65435,1.84862\n172,10,1.64188,1.86158\n172,11,1.62932,1.87467\n172,12,1.61667,1.88791\n172,13,1.60393,1.90129\n172,14,1.59111,1.91482\n172,15,1.57819,1.92848\n172,16,1.5652,1.94228\n172,17,1.55212,1.95623\n172,18,1.53897,1.9703\n172,19,1.52574,1.98451\n172,20,1.51243,1.99884\n172,21,1.49906,2.01331\n173,2,1.73964,1.76288\n173,3,1.72794,1.77469\n173,4,1.71615,1.78664\n173,5,1.70424,1.79877\n173,6,1.69224,1.81103\n173,7,1.68013,1.82345\n173,8,1.66793,1.83602\n173,9,1.65564,1.84874\n173,10,1.64325,1.8616\n173,11,1.63076,1.87461\n173,12,1.61819,1.88777\n173,13,1.60552,1.90106\n173,14,1.59278,1.9145\n173,15,1.57994,1.92808\n173,16,1.56704,1.94179\n173,17,1.55404,1.95564\n173,18,1.54097,1.96961\n173,19,1.52782,1.98372\n173,20,1.5146,1.99796\n173,21,1.5013,2.01233\n174,2,1.74042,1.76352\n174,3,1.72879,1.77526\n174,4,1.71706,1.78715\n174,5,1.70523,1.79919\n174,6,1.69329,1.81139\n174,7,1.68126,1.82373\n174,8,1.66913,1.83622\n174,9,1.65691,1.84885\n174,10,1.64459,1.86165\n174,11,1.63219,1.87456\n174,12,1.61969,1.88764\n174,13,1.60711,1.90085\n174,14,1.59443,1.91419\n174,15,1.58168,1.92768\n174,16,1.56884,1.9413\n174,17,1.55593,1.95506\n174,18,1.54294,1.96894\n174,19,1.52987,1.98296\n174,20,1.51673,1.9971\n174,21,1.50352,2.01136\n175,2,1.74119,1.76416\n175,3,1.72963,1.77583\n175,4,1.71796,1.78765\n175,5,1.7062,1.79961\n175,6,1.69433,1.81174\n175,7,1.68237,1.824\n175,8,1.67031,1.83641\n175,9,1.65817,1.84898\n175,10,1.64593,1.86168\n175,11,1.63359,1.87452\n175,12,1.62117,1.8875\n175,13,1.60867,1.90063\n175,14,1.59607,1.91389\n175,15,1.58339,1.92729\n175,16,1.57064,1.94082\n175,17,1.5578,1.95448\n175,18,1.54489,1.96827\n175,19,1.5319,1.98219\n175,20,1.51885,1.99624\n175,21,1.50572,2.01041\n176,2,1.74195,1.76479\n176,3,1.73046,1.77639\n176,4,1.71885,1.78814\n176,5,1.70716,1.80004\n176,6,1.69536,1.81208\n176,7,1.68348,1.82427\n176,8,1.67149,1.83662\n176,9,1.65941,1.8491\n176,10,1.64724,1.86172\n176,11,1.63499,1.87448\n176,12,1.62264,1.88738\n176,13,1.61021,1.90042\n176,14,1.59769,1.9136\n176,15,1.58509,1.92691\n176,16,1.57241,1.94035\n176,17,1.55966,1.95392\n176,18,1.54682,1.96762\n176,19,1.53392,1.98145\n176,20,1.52094,1.9954\n176,21,1.50789,2.00947\n177,2,1.7427,1.76541\n177,3,1.73127,1.77694\n177,4,1.71974,1.78863\n177,5,1.70812,1.80045\n177,6,1.69639,1.81243\n177,7,1.68457,1.82455\n177,8,1.67265,1.83681\n177,9,1.66064,1.84921\n177,10,1.64855,1.86176\n177,11,1.63636,1.87444\n177,12,1.62409,1.88727\n177,13,1.61174,1.90022\n177,14,1.5993,1.91331\n177,15,1.58677,1.92653\n177,16,1.57418,1.93988\n177,17,1.56149,1.95337\n177,18,1.54874,1.96698\n177,19,1.53591,1.98071\n177,20,1.52301,1.99457\n177,21,1.51004,2.00855\n178,2,1.74345,1.76603\n178,3,1.73209,1.7775\n178,4,1.72063,1.78911\n178,5,1.70906,1.80087\n178,6,1.69741,1.81277\n178,7,1.68565,1.82482\n178,8,1.6738,1.83701\n178,9,1.66187,1.84934\n178,10,1.64985,1.86181\n178,11,1.63773,1.87441\n178,12,1.62553,1.88715\n178,13,1.61325,1.90002\n178,14,1.60088,1.91303\n178,15,1.58844,1.92617\n178,16,1.57591,1.93943\n178,17,1.56331,1.95283\n178,18,1.55063,1.96635\n178,19,1.53788,1.97999\n178,20,1.52506,1.99376\n178,21,1.51217,2.00764\n179,2,1.74419,1.76665\n179,3,1.73289,1.77804\n179,4,1.72149,1.78959\n179,5,1.71,1.80128\n179,6,1.69841,1.81311\n179,7,1.68672,1.82509\n179,8,1.67495,1.83721\n179,9,1.66308,1.84945\n179,10,1.65113,1.86184\n179,11,1.63908,1.87437\n179,12,1.62696,1.88703\n179,13,1.61475,1.89982\n179,14,1.60245,1.91275\n179,15,1.59009,1.9258\n179,16,1.57763,1.93899\n179,17,1.5651,1.95229\n179,18,1.5525,1.96573\n179,19,1.53983,1.97928\n179,20,1.52709,1.99296\n179,21,1.51427,2.00675\n180,2,1.74493,1.76726\n180,3,1.73369,1.7786\n180,4,1.72236,1.79007\n180,5,1.71092,1.8017\n180,6,1.6994,1.81346\n180,7,1.68779,1.82536\n180,8,1.67608,1.8374\n180,9,1.66428,1.84959\n180,10,1.65239,1.8619\n180,11,1.64043,1.87435\n180,12,1.62837,1.88692\n180,13,1.61623,1.89964\n180,14,1.60401,1.91248\n180,15,1.59171,1.92545\n180,16,1.57934,1.93855\n180,17,1.56688,1.95177\n180,18,1.55436,1.96511\n180,19,1.54176,1.97858\n180,20,1.5291,1.99217\n180,21,1.51636,2.00587\n181,2,1.74565,1.76787\n181,3,1.73448,1.77913\n181,4,1.72321,1.79055\n181,5,1.71184,1.8021\n181,6,1.70039,1.8138\n181,7,1.68883,1.82564\n181,8,1.6772,1.8376\n181,9,1.66547,1.84971\n181,10,1.65366,1.86194\n181,11,1.64175,1.87431\n181,12,1.62977,1.88682\n181,13,1.6177,1.89945\n181,14,1.60555,1.91221\n181,15,1.59333,1.9251\n181,16,1.58102,1.93812\n181,17,1.56865,1.95125\n181,18,1.5562,1.96451\n181,19,1.54367,1.97789\n181,20,1.53108,1.99139\n181,21,1.51842,2.005\n182,2,1.74638,1.76846\n182,3,1.73527,1.77967\n182,4,1.72406,1.79102\n182,5,1.71276,1.80251\n182,6,1.70137,1.81413\n182,7,1.68988,1.8259\n182,8,1.67831,1.83779\n182,9,1.66665,1.84983\n182,10,1.6549,1.86199\n182,11,1.64306,1.8743\n182,12,1.63115,1.88672\n182,13,1.61915,1.89927\n182,14,1.60708,1.91196\n182,15,1.59492,1.92476\n182,16,1.58269,1.93769\n182,17,1.57039,1.95074\n182,18,1.55801,1.96392\n182,19,1.54556,1.97722\n182,20,1.53304,1.99062\n182,21,1.52046,2.00415\n183,2,1.7471,1.76906\n183,3,1.73604,1.78021\n183,4,1.7249,1.7915\n183,5,1.71367,1.80291\n183,6,1.70234,1.81447\n183,7,1.69091,1.82617\n183,8,1.6794,1.83799\n183,9,1.66781,1.84995\n183,10,1.65613,1.86205\n183,11,1.64437,1.87427\n183,12,1.63252,1.88662\n183,13,1.62059,1.8991\n183,14,1.60858,1.9117\n183,15,1.5965,1.92442\n183,16,1.58435,1.93727\n183,17,1.57211,1.95025\n183,18,1.5598,1.96333\n183,19,1.54743,1.97655\n183,20,1.53499,1.98987\n183,21,1.52248,2.00331\n184,2,1.74781,1.76965\n184,3,1.73681,1.78074\n184,4,1.72574,1.79195\n184,5,1.71456,1.80332\n184,6,1.70329,1.81481\n184,7,1.69194,1.82643\n184,8,1.6805,1.83819\n184,9,1.66896,1.85008\n184,10,1.65735,1.8621\n184,11,1.64565,1.87425\n184,12,1.63387,1.88652\n184,13,1.62201,1.89892\n184,14,1.61008,1.91145\n184,15,1.59807,1.9241\n184,16,1.58598,1.93687\n184,17,1.57382,1.94976\n184,18,1.56159,1.96276\n184,19,1.54929,1.97588\n184,20,1.53691,1.98912\n184,21,1.52448,2.00248\n185,2,1.74851,1.77024\n185,3,1.73759,1.78127\n185,4,1.72656,1.79242\n185,5,1.71545,1.80371\n185,6,1.70424,1.81514\n185,7,1.69295,1.8267\n185,8,1.68157,1.83838\n185,9,1.6701,1.85021\n185,10,1.65856,1.86215\n185,11,1.64693,1.87424\n185,12,1.63522,1.88644\n185,13,1.62343,1.89876\n185,14,1.61156,1.91121\n185,15,1.59962,1.92377\n185,16,1.5876,1.93646\n185,17,1.57551,1.94928\n185,18,1.56335,1.9622\n185,19,1.55112,1.97525\n185,20,1.53882,1.98839\n185,21,1.52646,2.00166\n186,2,1.74921,1.77082\n186,3,1.73835,1.78178\n186,4,1.72738,1.79288\n186,5,1.71633,1.80411\n186,6,1.70519,1.81547\n186,7,1.69396,1.82696\n186,8,1.68264,1.83858\n186,9,1.67124,1.85034\n186,10,1.65976,1.86222\n186,11,1.64819,1.87422\n186,12,1.63655,1.88635\n186,13,1.62482,1.8986\n186,14,1.61303,1.91097\n186,15,1.60115,1.92346\n186,16,1.5892,1.93607\n186,17,1.57718,1.94881\n186,18,1.56509,1.96165\n186,19,1.55293,1.97461\n186,20,1.54071,1.98768\n186,21,1.52841,2.00086\n187,2,1.74991,1.7714\n187,3,1.7391,1.7823\n187,4,1.72819,1.79334\n187,5,1.7172,1.8045\n187,6,1.70612,1.8158\n187,7,1.69495,1.82723\n187,8,1.6837,1.83878\n187,9,1.67236,1.85046\n187,10,1.66095,1.86227\n187,11,1.64945,1.8742\n187,12,1.63786,1.88626\n187,13,1.62621,1.89843\n187,14,1.61448,1.91074\n187,15,1.60267,1.92315\n187,16,1.59079,1.93568\n187,17,1.57884,1.94834\n187,18,1.56682,1.9611\n187,19,1.55473,1.97397\n187,20,1.54258,1.98697\n187,21,1.53035,2.00007\n188,2,1.75059,1.77197\n188,3,1.73984,1.78282\n188,4,1.729,1.79379\n188,5,1.71806,1.80489\n188,6,1.70704,1.81613\n188,7,1.69594,1.82749\n188,8,1.68475,1.83897\n188,9,1.67348,1.85059\n188,10,1.66212,1.86233\n188,11,1.65069,1.8742\n188,12,1.63918,1.88617\n188,13,1.62758,1.89829\n188,14,1.61592,1.91051\n188,15,1.60418,1.92284\n188,16,1.59236,1.93531\n188,17,1.58048,1.94788\n188,18,1.56853,1.96057\n188,19,1.55651,1.97336\n188,20,1.54443,1.98627\n188,21,1.53228,1.99929\n189,2,1.75128,1.77254\n189,3,1.74058,1.78332\n189,4,1.7298,1.79424\n189,5,1.71892,1.80528\n189,6,1.70796,1.81645\n189,7,1.69691,1.82775\n189,8,1.68579,1.83917\n189,9,1.67458,1.85072\n189,10,1.66328,1.86239\n189,11,1.65192,1.87419\n189,12,1.64047,1.8861\n189,13,1.62894,1.89813\n189,14,1.61734,1.91028\n189,15,1.60567,1.92255\n189,16,1.59393,1.93493\n189,17,1.58211,1.94743\n189,18,1.57022,1.96003\n189,19,1.55828,1.97275\n189,20,1.54625,1.98558\n189,21,1.53417,1.99852\n190,2,1.75196,1.77311\n190,3,1.74132,1.78383\n190,4,1.73059,1.79468\n190,5,1.71977,1.80567\n190,6,1.70887,1.81678\n190,7,1.69789,1.82801\n190,8,1.68682,1.83937\n190,9,1.67567,1.85086\n190,10,1.66444,1.86246\n190,11,1.65313,1.87418\n190,12,1.64175,1.88602\n190,13,1.63028,1.89798\n190,14,1.61875,1.91007\n190,15,1.60714,1.92226\n190,16,1.59547,1.93456\n190,17,1.58372,1.94699\n190,18,1.5719,1.95952\n190,19,1.56001,1.97216\n190,20,1.54807,1.9849\n190,21,1.53605,1.99776\n191,2,1.75262,1.77366\n191,3,1.74204,1.78433\n191,4,1.73138,1.79513\n191,5,1.72061,1.80605\n191,6,1.70978,1.81711\n191,7,1.69884,1.82827\n191,8,1.68784,1.83957\n191,9,1.67675,1.85098\n191,10,1.66558,1.86252\n191,11,1.65434,1.87418\n191,12,1.64301,1.88595\n191,13,1.63162,1.89784\n191,14,1.62015,1.90985\n191,15,1.60861,1.92197\n191,16,1.59699,1.93421\n191,17,1.58531,1.94654\n191,18,1.57356,1.959\n191,19,1.56175,1.97157\n191,20,1.54987,1.98424\n191,21,1.53792,1.99702\n192,2,1.75329,1.77422\n192,3,1.74277,1.78483\n192,4,1.73215,1.79557\n192,5,1.72145,1.80644\n192,6,1.71066,1.81743\n192,7,1.6998,1.82854\n192,8,1.68885,1.83977\n192,9,1.67783,1.85111\n192,10,1.66671,1.86259\n192,11,1.65553,1.87418\n192,12,1.64427,1.88588\n192,13,1.63294,1.8977\n192,14,1.62153,1.90964\n192,15,1.61006,1.92168\n192,16,1.59851,1.93385\n192,17,1.58689,1.94612\n192,18,1.5752,1.9585\n192,19,1.56345,1.97099\n192,20,1.55165,1.98358\n192,21,1.53977,1.99628\n193,2,1.75396,1.77477\n193,3,1.74348,1.78533\n193,4,1.73293,1.79601\n193,5,1.72228,1.80682\n193,6,1.71155,1.81775\n193,7,1.70074,1.82879\n193,8,1.68986,1.83996\n193,9,1.67889,1.85125\n193,10,1.66784,1.86266\n193,11,1.65672,1.87417\n193,12,1.64553,1.88581\n193,13,1.63425,1.89756\n193,14,1.6229,1.90943\n193,15,1.61149,1.92141\n193,16,1.6,1.93349\n193,17,1.58845,1.94569\n193,18,1.57683,1.958\n193,19,1.56515,1.97041\n193,20,1.55341,1.98293\n193,21,1.54159,1.99555\n194,2,1.75461,1.77533\n194,3,1.74419,1.78583\n194,4,1.73369,1.79645\n194,5,1.7231,1.80719\n194,6,1.71243,1.81806\n194,7,1.70168,1.82905\n194,8,1.69085,1.84016\n194,9,1.67994,1.85138\n194,10,1.66895,1.86272\n194,11,1.65789,1.87418\n194,12,1.64676,1.88575\n194,13,1.63554,1.89743\n194,14,1.62427,1.90923\n194,15,1.61291,1.92114\n194,16,1.60149,1.93315\n194,17,1.59001,1.94529\n194,18,1.57845,1.95752\n194,19,1.56683,1.96985\n194,20,1.55514,1.9823\n194,21,1.54341,1.99484\n195,2,1.75526,1.77586\n195,3,1.7449,1.78632\n195,4,1.73445,1.79688\n195,5,1.72392,1.80757\n195,6,1.7133,1.81838\n195,7,1.70261,1.8293\n195,8,1.69183,1.84035\n195,9,1.68099,1.85151\n195,10,1.67005,1.86279\n195,11,1.65905,1.87418\n195,12,1.64798,1.88569\n195,13,1.63683,1.89731\n195,14,1.62561,1.90903\n195,15,1.61432,1.92087\n195,16,1.60296,1.93282\n195,17,1.59154,1.94487\n195,18,1.58005,1.95704\n195,19,1.56849,1.9693\n195,20,1.55687,1.98166\n195,21,1.5452,1.99413\n196,2,1.75591,1.7764\n196,3,1.74559,1.7868\n196,4,1.7352,1.79731\n196,5,1.72473,1.80794\n196,6,1.71416,1.81869\n196,7,1.70352,1.82956\n196,8,1.69282,1.84055\n196,9,1.68202,1.85164\n196,10,1.67115,1.86286\n196,11,1.6602,1.87419\n196,12,1.64919,1.88563\n196,13,1.6381,1.89718\n196,14,1.62695,1.90884\n196,15,1.61571,1.92061\n196,16,1.60442,1.93249\n196,17,1.59306,1.94447\n196,18,1.58164,1.95656\n196,19,1.57014,1.96875\n196,20,1.55859,1.98104\n196,21,1.54697,1.99344\n197,2,1.75655,1.77694\n197,3,1.74629,1.78728\n197,4,1.73595,1.79774\n197,5,1.72553,1.80831\n197,6,1.71502,1.819\n197,7,1.70444,1.82982\n197,8,1.69378,1.84074\n197,9,1.68305,1.85178\n197,10,1.67223,1.86293\n197,11,1.66135,1.87419\n197,12,1.65039,1.88558\n197,13,1.63936,1.89705\n197,14,1.62827,1.90865\n197,15,1.6171,1.92036\n197,16,1.60586,1.93216\n197,17,1.59456,1.94408\n197,18,1.5832,1.95609\n197,19,1.57177,1.96821\n197,20,1.56028,1.98043\n197,21,1.54873,1.99275\n198,2,1.75719,1.77747\n198,3,1.74698,1.78776\n198,4,1.73669,1.79817\n198,5,1.72632,1.80868\n198,6,1.71588,1.81932\n198,7,1.70534,1.83007\n198,8,1.69474,1.84094\n198,9,1.68406,1.85192\n198,10,1.6733,1.86301\n198,11,1.66248,1.8742\n198,12,1.65159,1.88552\n198,13,1.64061,1.89694\n198,14,1.62957,1.90846\n198,15,1.61846,1.9201\n198,16,1.6073,1.93184\n198,17,1.59605,1.94368\n198,18,1.58476,1.95563\n198,19,1.57338,1.96769\n198,20,1.56196,1.97983\n198,21,1.55047,1.99208\n199,2,1.75781,1.778\n199,3,1.74766,1.78824\n199,4,1.73743,1.79858\n199,5,1.72711,1.80905\n199,6,1.71671,1.81963\n199,7,1.70624,1.83032\n199,8,1.69569,1.84113\n199,9,1.68507,1.85205\n199,10,1.67437,1.86308\n199,11,1.6636,1.87422\n199,12,1.65277,1.88547\n199,13,1.64185,1.89683\n199,14,1.63088,1.90828\n199,15,1.61983,1.91985\n199,16,1.60872,1.93152\n199,17,1.59754,1.9433\n199,18,1.58629,1.95518\n199,19,1.57499,1.96716\n199,20,1.56362,1.97923\n199,21,1.5522,1.99141\n200,2,1.75844,1.77852\n200,3,1.74833,1.78871\n200,4,1.73815,1.79901\n200,5,1.72789,1.80942\n200,6,1.71755,1.81994\n200,7,1.70713,1.83057\n200,8,1.69663,1.84133\n200,9,1.68607,1.85219\n200,10,1.67543,1.86316\n200,11,1.66471,1.87423\n200,12,1.65394,1.88541\n200,13,1.64308,1.89671\n200,14,1.63216,1.9081\n200,15,1.62117,1.91961\n200,16,1.61011,1.93122\n200,17,1.599,1.94292\n200,18,1.58781,1.95473\n200,19,1.57657,1.96665\n200,20,1.56527,1.97865\n200,21,1.5539,1.99075\n'
durbin_watson = pd.read_csv(StringIO(csv_content))

# THIS FUNCTIONS ARE GOING TO BE GLOBAL
class global_functions:
    # Function for selecting the "y" column in the data frame (dependient variable)
    def select_y_var(df):
        [print(f"{i+1}. {k}") for i,k in enumerate(df.columns)]
        x = input("Select y variable:")
        y_index = int(x)-1
        y_name = df.iloc[:,y_index:y_index+1].columns[0]
        return {'y_index':int(x)-1,'y_name':y_name}

    # Function to make the different scatter plots MULTIPLE AND SIMPLE REGRESSION MODELS
    def scatter_plot(df,title):
        # First Column of the data frame is going to be X axis an second column is going to be Y axis
        x_name = df.columns[0]
        y_name = df.columns[1]

        # Creating Scatter Plot
        fig = px.scatter(df, x=x_name, y=y_name, template='plotly_dark', 
                        color=y_name, hover_data={x_name: True, y_name: True})


        # Configurar el título con Plotly Graph Objects
        fig.update_layout(title=dict(text=f"<b>{title}</b>",
                                    x=0.5,  # Centering title horizontaly
                                    y=0.95,  # Title aligned to the top of the plot
                                    xanchor='center',  # Horizontal anchor cenetered
                                    yanchor='top'))  # Vertical anchor at the top

        # Updating tooltip, color and size of the dots
        fig.update_traces(marker=dict(color='blue', size=8), hovertemplate=f'{x_name}: %{{x}}<br>{y_name}: %{{y}}', line=dict(dash='dot'))
        
        # Just for the Versus Fits and the Versus Order Plots, we are adding an horizontal dotted line.
        if title == 'Versus Fits' or title == 'Versus Order':
            # Adding horizontal dotted line.
            fig.add_shape(type='line',
                        x0=df[x_name].min(), x1=df[x_name].max(),
                        y0=0, y1=0,  # Adjusting de horizontal line to y=0
                        line=dict(color='white', dash='dot'))
        
        # Just for the Versus Order Plot, we are adding a line that follows all the points without smoothing lines
        if title == 'Versus Order':
            line_fig = px.line(df, x=x_name, y=y_name)
            for trace in line_fig.data:
                trace.update(line=dict(color='blue', width=2))
                fig.add_trace(trace)
        
        # Just for the Normal Probability Plot we are adding a tendence line.
        if title == 'Normal Probability Plot' or title == 'Correlation Plot':      
            # Calcular la línea de tendencia usando statsmodels
            X = sm.add_constant(df[x_name])  # Agregar una constante para el término independiente
            model = sm.OLS(df[y_name], X).fit()
            trendline = model.predict(X)
            if title == 'Normal Probability Plot':
                # Agregar la línea de tendencia al gráfico
                fig.add_trace(go.Scatter(x=df[x_name], y=trendline, mode='lines', name='OLS', line=dict(color='red', dash='dot')))
                fig.update_layout(showlegend=False)
            else:
                # Agregar la línea de tendencia al gráfico
                fig.add_trace(go.Scatter(x=df[x_name], y=trendline, mode='lines', name='OLS', line=dict(color='white', dash='dot')))
                fig.update_traces()
                fig.update_layout(showlegend=False, title=dict(text=f"<b>Correlation Plot ({df.corr()[df.columns[0]][df.columns[1]]*100:.2f}%)</b>", x=.5))
        return fig

    # RESIDUALS DISTRIBUTED NORMAL WITH MEAN 0, VARIANCE OF THE RESIDUALS
    # NORMAL DISTRIBUTION MEAN 0
    # H0: Residuals come from a Normal distribution with 0 mean
    # Ha: Residuals come from anothe distribution
    def normality_0_mean(anova_table,residuals):
        n = len(residuals)
        classes = int(n**(1/2))

        # Funcion Para Redondear hacia Arriba
        def redondear_hacia_arriba(numero, decimales=4):
            if isinstance(numero, float):
                parte_decimal = numero - int(numero)
                if parte_decimal > 0:
                    redondeado = math.ceil(numero * 10**decimales) / 10**decimales
                    return round(redondeado, decimales)
            return numero

        width = redondear_hacia_arriba((residuals.max() - residuals.min())/classes)
        linf = [residuals.min()] + [residuals.min() + width*i for i in range(1,classes)]
        lsup = [residuals.min() + width*i for i in range(1,classes)] + [residuals.max()]
        
        limits = [residuals.min()] + [residuals.min() + width*i for i in range(1,classes)] + [residuals.max()]
        intervals = [f"({limits[i].__round__(4)}, {limits[i+1].__round__(4)})" for i in range(len(limits)-1)]
        
        # List of Frequencies by Interval
        frequence = [0]*classes

        # Counting Frequence in each Interval
        for value in residuals:
            for i in range(classes):
                if linf[i] <= value < lsup[i]:
                    frequence[i] += 1
                    break
        frequence[-1] += 1
        
        # Data frame with frecuence and interval of values, for histogram
        histogram_df = pd.DataFrame({'Residuals':intervals,'Frequence':frequence})
        
        # Histogram. Using function in class plots
        histogram_plt = plots.histogram(histogram_df, 'Histogram')
        
        # Residuals Standard Deviation
        residuals_std = (anova_table['half_square'][1])**(1/2)

        # Cumulative Distribution Function
        cdf = [stats.norm.cdf(lsup[0], scale=residuals_std, loc=0)] + [stats.norm.cdf(lsup[i], scale=residuals_std, loc=0) - stats.norm.cdf(linf[i], scale=residuals_std, loc=0) for i in range(1,classes-1)] + [1-stats.norm.cdf(lsup[classes-2], scale=residuals_std, loc=0)]

        # Expected Frequency
        exp_freq = [i*n for i in cdf]

        quotient = [np.square(exp_freq[i] - frequence[i])/exp_freq[i] for i in range(classes)]

        test_statistic = sum(quotient)

        # Chi Square Inverse Functions with alpha = 0.05 and n = classes - 2
        chi_square = stats.chi2.isf(.05, classes-2)

        if test_statistic > chi_square:
            normal_0_mean_hypothesis = f"{test_statistic.__round__(4)} > {chi_square.__round__(4)}, Residuals come from another distribution"
        else:
            normal_0_mean_hypothesis = f"{test_statistic.__round__(4)} < {chi_square.__round__(4)}, Residuals come from a Normal distribution with mean 0"
            
        return normal_0_mean_hypothesis, histogram_plt
    
    def incorrelation_assumption(residuals,k):
        # INCORRELATION ASSUMPTION
        # H0: p = 0, which means the analysed data doesn't have correlation
        # Ha: p > 0, which means the analysed data has correlation
        # Reject H0 if d < dL
        # Don't rehect H0 if d > dU
        # Inconclusive test if dL < d < dU
        n = len(residuals)
        
        d = sum(np.square([residuals[i+1] - residuals[i] for i in range(n-1)]))/sum(np.square(residuals))

        finding_row = durbin_watson.loc[(durbin_watson['sample_size'] == n) & (durbin_watson['n_terms'] == k)].reset_index(drop=True)
        dL = finding_row['DL'][0]
        dU = finding_row['DU'][0]

        if d < dL:
            incorrelation_test = f"{d} < {dL}, Correlated data."
        elif d > dU:
            incorrelation_test = f"{d} > {dU}, Incorrelated data."
        else:
            incorrelation_test = f"{dL} < {d} < {dU}, Inconclusive test."
            
        return incorrelation_test

    # ATYPICAL DATA IN THE SAMPLE
    def atypical_data(residuals, residuals_var, hi):
        # ATYPICAL DATA
        # Standarized Residuals
        standarized_residuals = [(value)/(residuals_var*(1-hi[i]))**.5 for i,value in enumerate(residuals)]
        # Finding Atypical Data
        atypical_data = {'Obs':[],'Resid':[],'Std Resid':[],'hi':[]}
        for i,value in enumerate(standarized_residuals):
            if abs(value) > 3:
                atypical_data['Obs'].append(i+1)
                atypical_data['Resid'].append(residuals[i])
                atypical_data['Std Resid'].append(value)
                atypical_data['hi'].append(hi[i])
        atypical_data = pd.DataFrame(atypical_data)
        
        # If there is not atypical data, it will tell the user
        if len(atypical_data['Obs']) == 0:
            atypical_data = "There is not atypical data in the sample"
            
        return atypical_data
    
    def qqplot(residuals,residuals_variance):
        # NORMALITY OF THE RESIDUALS
        # Sorting residuals ascendently
        sorted_residuals = np.sort(residuals)
        # k is the probability P[Z < Zk] = k
        k = [(i-.375)/(len(residuals)+.25) for i in range(1,len(residuals)+1)]
        # Now we find Zk
        Zk = [stats.norm.isf(1-i) for i in k]
        # Finally we calculate the expected value if the residuals where distributed normally
        exp_value = [i*residuals_variance**.5 for i in Zk]
        # Data Frame to use the scatter plot function
        qqplot_df = pd.DataFrame({'Residuals':sorted_residuals,'Expected Value':exp_value})

        # Normal Probability Plot
        normal_prob_plt = global_functions.scatter_plot(qqplot_df,'Normal Probability Plot')
        
        return normal_prob_plt

# THIS FUNCTIONS CAN BE USED IN THE SIMPLE REGRESSION MODELING, SOME OF THEM IN THE MULTIPLE REGRESSION MODELING
class linearization:
    # Function to determine the coefficients and the estimated y (JUST FOR SIMPLE REGRESSION MODELING)
    def linearizable_model(df):
        # LINEAR MODEL: y = b0 + b1 * x
        # ln(y) = ln(b0) + ln(b1) + ln(x)
        # Values of the constants of the linear model
        b1 = (np.sum(df['x']*df['y']) - np.sum(df['x'])*np.sum(df['y'])/len(df))/(np.sum(np.square(df['x']))-np.sum(df['x'])**2/len(df))
        b0 = np.average(df['y']) - b1 * np.average(df['x'])
        estimated_y = b0 + b1 * df['x']
        return b0, b1, estimated_y
    
    # This function calculates the anova table (JUST FOR SIMPLE REGRESSION MODELING)
    def anova_table(n, y, estimated_y, y_avg):
        # ANOVA table
        source_of_variation = pd.Series(['Regression', 'Residuals', 'Total'])

        SSR = np.sum(np.square(estimated_y-y_avg))
        SSE = np.sum(np.square(y - estimated_y))
        SST = np.sum(np.square(y - y_avg))


        degrees_of_freedom = pd.Series([1, n-2, n-1])

        sum_of_squares = pd.Series([SSR, SSE, SST])

        MSR = SSR/1
        MSE = SSE/(n-2)

        median_square = pd.Series([MSR, MSE])

        # Test Statistic
        F0 = pd.Series(MSR/MSE)
        
        # ANOVA TABLE DATAFRAME
        anova_table = pd.DataFrame({'source_of_variation':source_of_variation, 'degrees_of_freedom':degrees_of_freedom, 'sum_of_squares':sum_of_squares, 'median_square':median_square, 'F0':F0})

        # Inverse F Distribution
        F_alpha = stats.f.isf(.05, 1, n-2)

        R_square = SSR/SST
        
        return anova_table, F_alpha, R_square
    
    # This function calculates the confidence intervals of the coefficients for the model (JUST FOR SIMPLE REGRESSION MODELING)
    def confidence_intervals(b0, b1, n, x_avg, MSE, xi):
        # b1 defines as:
        left_interval_b1 = b1 - stats.t.isf(.05/2, n-2) * np.sqrt(MSE/np.sum(np.square(xi - x_avg)))
        right_interval_b1 = b1 + stats.t.isf(.05/2, n-2) * np.sqrt(MSE/np.sum(np.square(xi - x_avg)))

        # b0 defines as:
        left_interval_b0 = b0 - stats.t.isf(.05/2, n-2) * np.sqrt(MSE * (1/n + x_avg**2/np.sum(np.square(xi - x_avg))))
        right_interval_b0 = b0 + stats.t.isf(.05/2, n-2) * np.sqrt(MSE * (1/n + x_avg**2/np.sum(np.square(xi - x_avg))))
        
        return {"li_b0":left_interval_b0, "ri_b0":right_interval_b0, "li_b1":left_interval_b1, "ri_b1":right_interval_b1}
    
    # This function calculates the performance level of the regression (JUST FOR SIMPLE REGRESSION MODELING)
    def performance_level(r_square):
        if r_square > .9:
            return "Very Good"
        elif r_square > .7:
            return "Good"
        elif r_square > .4:
            return "Moderate"
        elif r_square > .2:
            return "Low"
        else:
            return "Null"
    
    # This functions does the significance test (USED FOR SIMPLE AND MULTIPLE REGRESION MODELING)
    def significance_test(F0, F_alpha):
        # SIGNIFICANCE TEST
        # H0: b1 = 0 which means the regression is not significative. This also means the independient variable does not predict the dependient variable
        # Ha: b1 != 0 which means the regression is significative. This also means the independient variable predict the dependient variable

        # We reject the null hipothesis (H0) if F0 > F.05,1,n-2
        if F0 > F_alpha:
            return f"{F0.__round__(4)} > {F_alpha.__round__(4)}, Significant Regression"
        else:
            return f"{F0.__round__(4)} < {F_alpha.__round__(4)}, Insignificant Regression"

# THIS CLASS HAS THE REGRESSION MODELS FOR SIMPLE REGRESSION MODELING (LINEAR, POWER, EXPONENCIAL, LOGARITMIC, AND RECIPROCAL)
class RLS: 
    # LINEAR MODEL
    def linear_model_arg(df, x, y):
        linear_model_data = linearization.linearizable_model(df)

        b0 = linear_model_data[0]
        b1 = linear_model_data[1]
        
        y_avg = df['y'].mean()

        linear_model_anova = linearization.anova_table(len(df), df['y'], linear_model_data[2], y_avg)
        
        anova_table = linear_model_anova[0]
        f_alpha = linear_model_anova[1]
        r_square = linear_model_anova[2]
        
        MSE = linear_model_anova[0].loc[1,'median_square']
        n = len(df)
        x_avg = df['x'].mean()
        
        ci = linearization.confidence_intervals(b0, b1, n, x_avg, MSE,df['x'])
        
        estimated_ecuation = f'{y} = {b0.__round__(4)} + {b1.__round__(4)}*{x}'
        
        residuals = df['y'] - linear_model_data[2]
        
        return {"b0":b0, "b1":b1, "estimated_y":linear_model_data[2], "anova_table":anova_table, "r_square":r_square,"residuals_variance":MSE, "f_alpha":f_alpha, "confidence_intervals":ci, "estimated_ecuation":estimated_ecuation, "residuals":residuals, "forecast_y":linear_model_data[2]}
    
    # POWER MODEL
    def power_model_arg(df, x, y):
        # power model
        lnx = np.log(df['x'])
        lny = np.log(df['y'])

        df_power_model = pd.DataFrame({'x':lnx, 'y':lny})
        power_model_data = linearization.linearizable_model(df_power_model)

        e = np.e
        b0 = e**power_model_data[0]
        b1 = power_model_data[1]

        y_power_model = b0 * df['x']**power_model_data[1]
        power_model_anova = linearization.anova_table(len(df), lny, power_model_data[2], power_model_data[2].mean())
        
        anova_table = power_model_anova[0]
        f_alpha = power_model_anova[1]
        r_square = power_model_anova[2]
        
        MSE = power_model_anova[0].loc[1,'median_square']
        n = len(df)
        x_avg = lnx.mean()
        
        ci = linearization.confidence_intervals(power_model_data[0], b1, n, x_avg, MSE, lnx)
        
        estimated_ecuation = f'{y} = {b0.__round__(4)}*{x}^{b1.__round__(4)}'
        
        residuals = lny - power_model_data[2]
        
        return {"b0":b0, "b1":b1, "estimated_y":y_power_model, "anova_table":anova_table, "r_square":r_square, "residuals_variance":MSE , "f_alpha":f_alpha, "confidence_intervals":ci, "estimated_ecuation":estimated_ecuation, "residuals":residuals, "forecast_y":power_model_data[2]}
    
    # EXPONENCIAL MODEL
    def exp_model_arg(df, x, y):
        lny = np.log(df['y'])

        df_exp_model = pd.DataFrame({'x':df['x'], 'y':lny})
        exp_model_data = linearization.linearizable_model(df_exp_model)

        e = np.e
        b0 = e ** exp_model_data[0]
        b1 = exp_model_data[1]

        y_exp_model = b0 * e ** (b1 * df['x'])
        exp_model_anova = linearization.anova_table(len(df), lny, exp_model_data[2], exp_model_data[2].mean())
        
        anova_table = exp_model_anova[0]
        f_alpha = exp_model_anova[1]
        r_square = exp_model_anova[2]
        
        MSE = exp_model_anova[0].loc[1,'median_square']
        n = len(df)
        x_avg = df['x'].mean()
        
        ci = linearization.confidence_intervals(exp_model_data[0], b1, n, x_avg, MSE, df['x'])
        
        estimated_ecuation = f'{y} = {b0.__round__(4)}*e^({b1.__round__(4)}*{x})'
        
        residuals = lny - exp_model_data[2]
        
        return {"b0":b0, "b1":b1, "estimated_y":y_exp_model, "anova_table":anova_table, "r_square":r_square, "residuals_variance":MSE, "f_alpha":f_alpha, "confidence_intervals":ci, "estimated_ecuation":estimated_ecuation,"residuals":residuals, "forecast_y":exp_model_data[2]}
    
    # LOGARITMIC MODEL
    def log_model_arg(df, x, y):
        lnx = np.log(df['x'])

        df_log_model = pd.DataFrame({'x':lnx, 'y':df['y']})
        log_model_data = linearization.linearizable_model(df_log_model)

        b0 = log_model_data[0]
        b1 = log_model_data[1]

        y_log_model = b0 + b1 * lnx
        log_model_anova = linearization.anova_table(len(df), df['y'], log_model_data[2], log_model_data[2].mean())
        
        anova_table = log_model_anova[0]
        f_alpha = log_model_anova[1]
        r_square = log_model_anova[2]
        
        MSE = log_model_anova[0].loc[1,'median_square']
        n = len(df)
        x_avg = lnx.mean()
        
        ci = linearization.confidence_intervals(b0, b1, n, x_avg, MSE, lnx)
        
        estimated_ecuation = f'{y} = {b0.__round__(4)} + {b1.__round__(4)}*ln({x})'
        
        residuals = df['y'] - log_model_data[2]
        
        return {"b0":b0, "b1":b1, "estimated_y":y_log_model, "anova_table":anova_table, "r_square":r_square, "residuals_variance":MSE, "f_alpha":f_alpha, "confidence_intervals":ci, "estimated_ecuation":estimated_ecuation, "residuals":residuals, "forecast_y":log_model_data[2]}
    
    # RECIPROCAL MODEL
    def rec_model_arg(df, x, y):
        y_rec = 1/df['y']
        x_rec = 1/df['x']

        df_rec_model = pd.DataFrame({'x':x_rec, 'y':y_rec})
        rec_model_data = linearization.linearizable_model(df_rec_model)

        b0 = rec_model_data[0]
        b1 = rec_model_data[1]

        y_rec_model = df['x'] / (b0*df['x'] - b1)
        rec_model_anova = linearization.anova_table(len(df), y_rec, rec_model_data[2], rec_model_data[2].mean())
        
        anova_table = rec_model_anova[0]
        f_alpha = rec_model_anova[1]
        r_square = rec_model_anova[2]
        
        MSE = rec_model_anova[0].loc[1,'median_square']
        n = len(df)
        x_avg = x_rec.mean()
        
        ci = linearization.confidence_intervals(b0, b1, n, x_avg, MSE, x_rec)
        
        estimated_ecuation = f'{y} = {x}/({b0.__round__(4)}*{x}-{b1.__round__(4)})'
        
        residuals = y_rec - rec_model_data[2]
        
        return {"b0":b0, "b1":b1, "estimated_y":y_rec_model, "anova_table":anova_table, "r_square":r_square, "residuals_variance":MSE, "f_alpha":f_alpha, "confidence_intervals":ci, "estimated_ecuation":estimated_ecuation, 'residuals':residuals, "forecast_y":rec_model_data[2]}
    
    # This function calculates the best model
    # The outputs for this functions are a Table with sumarry information about all the models, the best model with it's estimated ecuation, and the regression plot of the model.
    def best_model(df, calculations):
        # Name of the models
        Models = ['Linear', 'Power', 'Exponencial', 'Logaritmic', 'Reciprocal']

        # Estimated ecuation of the models
        est_ec = [ecuation['estimated_ecuation'] for ecuation in calculations]

        # List to present in a percentage format the performance of the models in the linearizable models table
        r_square = [f"{value['r_square']*100:.2f}%" for value in calculations]
        
        # Level of Performance of the models
        performance_level = [linearization.performance_level(i['r_square']) for i in calculations]

        # List to present in 4 decimls the variance of the models in the linearizable models table
        variance = [variance['residuals_variance'].__round__(4) for variance in calculations]
        
        # Confidence Intervals of the Coeficients
        ci_b0 = [f"{i['confidence_intervals']['li_b0'].__round__(4)} < b0 < {i['confidence_intervals']['ri_b0'].__round__(4)}" for i in calculations]
        ci_b1 = [f"{i['confidence_intervals']['li_b1'].__round__(4)} < b1 < {i['confidence_intervals']['ri_b1'].__round__(4)}" for i in calculations]
        
        # Significance Test
        significance_test = [linearization.significance_test(i['anova_table']['F0'][0], i['f_alpha']) for i in calculations]

        # linearizable Models Table
        lmt = pd.DataFrame({"Model":Models, "Estimated Ec.":est_ec, "R^2":r_square, 'Performance Level':performance_level, "Residuals Var":variance,"Significance Test":significance_test, "CI b0":ci_b0, "CI b1":ci_b1})

        # MODEL WITH THE BEST PERFORMANCE
        # List to find the model with the best performance
        r_square_list = [value['r_square'] for value in calculations]

        # Maximum performance of the list of models
        r_square_max = max(r_square_list)

        # Model/s with the best performance (index/es)
        r_square_max_index = [i for i, valor in enumerate(r_square_list) if valor == r_square_max]

        # List to find the model with the lowest residual variance
        residuals_var_list = [value['residuals_variance'] for value in calculations]

        # List to calculate the model with the lowest variance, in case there are 2 or more models with the same max performance
        if len(r_square_max_index) > 1:
            # Variance of the models that have the same performance, and the highest one
            restant_models = [residuals_var_list[i] for i in r_square_max_index]
            # Minimum value of variance the restant models
            min_var = min(restant_models)
            # Indexes of the models with the same variance, being the lowest of the list
            min_var_index = [i for i,valor in enumerate(restant_models) if valor == min_var]
            # BEST MODEL
            # Models/s with the best performance and lowest variance (Ideally it's gonna be one)
            best_model = lmt.iloc[min_var_index].reset_index(drop=True)
            
            # Best Model Regression Graph
            best_model_graph = plots.model_plot(df, calculations[min_var_index[0]])
            
        else:
            # Model with the best performance
            best_model = lmt.iloc[r_square_max_index,:].reset_index(drop=True)
            
            # Best Model Regression Graph
            best_model_graph = plots.model_plot(df, calculations[r_square_max_index[0]])
        
        return {'linearizable_models_table':lmt, 'best_model':best_model, 'best_model_graph':best_model_graph}

# THIS CLASS CONTAINS FUNCTIONS THAT RETURNS PLOTS, FOR BOTH SIMPLE AND MULTIPLE REGRESSION MODELS
class plots:
    # Matrix Plot. (JUST FOR MULTIPLE REGRESSION MODELS)
    def correl_matrix_plot(df):
        # Correlation Matrix
        corr_matrix = df.corr()

        # Transforming data to do a heatmap
        heatmap_df = corr_matrix.iloc[:,::-1].stack().reset_index()

        # Modifying the column names of the new df created
        heatmap_df.columns = ['x', 'y', 'z']

        # Making correlation values percentage
        heatmap_df['z'] = heatmap_df['z'] * 100

        # Doing the heatmap
        corr_heatmap = px.density_heatmap(heatmap_df, x='x', y='y', z='z',
                                        color_continuous_scale=[[0, 'blue'], [0.5, 'gray'], [1, 'red']],
                                        range_color=[-100, 100], text_auto=True, template="plotly_dark")

        # Title Centered
        corr_heatmap.update_layout(title=dict(text="Correlation Matrix", x=0.5))

        # Styling and modifying the tooltip
        corr_heatmap.update_traces(hovertemplate='(%{x}, %{y}) = %{z:.2f}%')

        # Styling text inside the rectangles as percentage
        corr_heatmap.update_traces(texttemplate='%{z:.2f}%')

        # Adding labels to axis
        corr_heatmap.update_layout(coloraxis_colorbar=dict(title='correlation'),
                                xaxis_title='', yaxis_title='')
        
        return corr_heatmap
    
    # Scatter Plot with tendence line with the regression model selected (JUST FOR SIMPLE REGRESSION MODELS)
    # It was used in the plot that contains subplots with all the regressions which is found in the best model option, and also for the select model option, where you only get the plot of the selected model.
    def model_plot(df, model):
        estimated_y = model['estimated_y']
        performance = model['r_square']
        y_name = 'y'
        estimated_y_name = {f'Estimated {y_name}'}

        # Crear el scatter plot con Plotly Express
        fig = px.scatter(df, x='x', y='y', template='plotly_dark', 
                        color='y', hover_data={'x': True, 'y': True})

        # Agregar la línea como una traza de scatter
        fig.add_trace(go.Scatter(x=df['x'], y=estimated_y, mode='lines', name='Estimated Y', line=dict(color='red')))

        # Configurar el título con Plotly Graph Objects
        fig.update_layout(title=dict(text=f"<b>Associated Model with {performance*100:.2f}% Performance: {model['estimated_ecuation']}</b>",
                                    x=0.5,  # Centrado horizontalmente
                                    y=0.95,  # Alineado en la parte superior
                                    xanchor='center',  # Anclaje horizontal al centro
                                    yanchor='top'))  # Anclaje vertical en la parte superior

        # Actualizar las trazas de los marcadores
        fig.update_traces(marker=dict(color='gray', opacity=.6, size=8), hovertemplate='x: %{x}<br>y: %{y}')
        
        return fig
    
    # Function to make a histogram, you have to insert a dataframe with the Intervals o value (Or wathever format you want your "X" axis to have) in the first column, and in the second column the frequencies
    def histogram(df, title):
        x_name = df.columns[0]
        y_name = df.columns[1]
        
        # Crear el histograma con Plotly Express
        fig = px.histogram(df, template='plotly_dark', title=title, x=x_name,y=y_name)
        
        # Actualizar el color de las barras y agregar borde negro
        fig.update_traces(marker=dict(color='blue', line=dict(color='white', width=1)))
        
        # Eliminar la leyenda
        fig.update_layout(showlegend=False)
        
        # Personalizar los nombres de los ejes
        fig.update_layout(
            xaxis_title=x_name,
            yaxis_title=y_name
        )
        
        # Centrar el título principal
        fig.update_layout(
            title=dict(
                text=title,
                x=0.5,  # Centrado horizontalmente
                y=0.95,  # Alineado en la parte superior
                xanchor='center',  # Anclaje horizontal al centro
                yanchor='top'  # Anclaje vertical en la parte superior
            ),
            bargap=0
        )
        
        return fig

# This is the official class for the simple regression model outputs
class webAppRegSimple:
    # best model function. Returns a list which contains the best model (With the estimated ecuation), the best model regression plot, a table with all the models summary, and the plot with all the regressions.
    def best_model(df):
        # Name of the models
        model_names = ['Linear', 'Power', 'Exponential', 'Logaritmic', 'Reciprocal']
        
        # List of All th models
        all_models = [RLS.linear_model_arg(df, 'x', 'y'), RLS.power_model_arg(df, 'x', 'y'), RLS.exp_model_arg(df, 'x', 'y'), RLS.log_model_arg(df, 'x', 'y'), RLS.rec_model_arg(df, 'x', 'y')]
        
        # Best Model
        best_model = RLS.best_model(df, all_models)

        # Best Model and its Estimated Ecuation
        best_model_result = f"Best Model: {best_model['best_model']['Model'][0]} Model\n\nEstimated Ecuation: {best_model['best_model']['Estimated Ec.'][0]}"

        # Regrssion Graph of the Best Model
        best_model_graph = best_model['best_model_graph'].update_layout(title=dict(text=f"{best_model['best_model']['Model'][0]} Model with {best_model['best_model']['R^2'][0]} Performance: {best_model['best_model']['Estimated Ec.'][0]}"))
        
        # Table with summarized information of the results of all the models
        summarized_models_table = best_model['linearizable_models_table']
        
        # Model Regression Graphs
        # Crear un subplot con 2 filas y 3 columnas
        fig = make_subplots(rows=2, cols=3)

        # Suponiendo que `all_models` es tu lista de modelos
        # all_models = [model1, model2, model3, model4, model5]
        # `df` es tu DataFrame con los datos

        for i, model in enumerate(all_models, start=1):
            row = (i - 1) // 3 + 1  # Calcular el número de fila (1, 1, 1, 2, 2)
            col = (i - 1) % 3 + 1   # Calcular el número de columna (1, 2, 3, 1, 2)
            
            # Obtener el gráfico para el modelo actual
            subplot = plots.model_plot(df, model)
            
            # Agregar el gráfico al subplot correspondiente
            for trace in subplot.data:
                fig.add_trace(trace, row=row, col=col)
            
            # Ajustar el título para que se alinee con el gráfico correspondiente
            # Usando coordenadas normalizadas
            x_pos = (col - 1) / 3 + 1 / 6  # Coordenadas normalizadas centradas para cada columna
            y_pos = 1.0 if row == 1 else 0.45
            
            # Agregar título al subgráfico
            fig.add_annotation(text=f"{model_names[i-1]} Regression Model", xref="paper", yref="paper",
                            x=x_pos, y=y_pos, xanchor="center", yanchor="bottom", showarrow=False)

        # Quitar la leyenda
        fig.update_layout(showlegend=False)

        # Agregar el título principal
        fig.update_layout(title_text="Regresion Models", title_x=0.5)

        # Aplicar el template 'plotly_dark'
        fig.update_layout(template='plotly_dark')
        
        return best_model_result, best_model_graph, summarized_models_table, fig
    
    # Select Model function. This function returns the estimated ecuation, significance test, r_square, performance level, residuals_variance (Variability of the residuals, also important for selecting a model),
    # Plot of the regression model, coefficient confidence intervals, anova table, the assumptions that the model must meet (Residuals distributed Normal with mean 0 and variance of the residuals, 
    # Incorrelated Data, and constant variance of the residuals), the qqplot, and the atypical values of the sample. 
    def select_model(df, model):
        if model == 'Linear':
            model_data = RLS.linear_model_arg(df, 'x', 'y')
        elif model == 'Power':
            model_data = RLS.power_model_arg(df, 'x', 'y')
        elif model == 'Exponential':
            model_data = RLS.exp_model_arg(df, 'x', 'y')
        elif model == 'Logaritmic':
            model_data = RLS.log_model_arg(df, 'x', 'y')
        elif model == 'Reciprocal':
            model_data = RLS.rec_model_arg(df, 'x', 'y')
        
        estimated_ecuation = model_data['estimated_ecuation']
        significance_test = linearization.significance_test(model_data['anova_table']['F0'][0],model_data['f_alpha'])
        r_square = model_data['r_square']
        performance_level = linearization.performance_level(r_square)
        residuals_variance = model_data['anova_table']['median_square'][1]
        model_graph = plots.model_plot(df,model_data)
        coeficient_intervals = f"Coeficient Condidence Intervals:\n{model_data['confidence_intervals']['li_b0'].__round__(4)} < b0 {model_data['confidence_intervals']['ri_b0'].__round__(4)}\n{model_data['confidence_intervals']['li_b1'].__round__(4)} < b1 {model_data['confidence_intervals']['ri_b1'].__round__(4)}"
        anova_table = model_data['anova_table']
    
        # ASSUMPTIONS
        # CONSTANT VARIANCE
        residuals = model_data['residuals']
        estimated_y = model_data['forecast_y']
        constant_variance_plot = global_functions.scatter_plot(pd.DataFrame({'Residuals':estimated_y, 'Fitted Value':residuals}),'Versus Fits')
        
        # NORMAL DISTRIBUTION MEAN 0
        # H0: Residuals come from a Normal distribution with 0 mean
        # Ha: Residuals come from anothe distribution
        n = len(df)
        classes = (n**(1/2)).__round__()

        # Funcion Para Redondear hacia Arriba
        def redondear_hacia_arriba(numero, decimales=4):
            if isinstance(numero, float):
                parte_decimal = numero - int(numero)
                if parte_decimal > 0:
                    redondeado = math.ceil(numero * 10**decimales) / 10**decimales
                    return round(redondeado, decimales)
            return numero

        width = redondear_hacia_arriba((residuals.max() - residuals.min())/classes)
        linf = [residuals.min()] + [residuals.min() + width*i for i in range(1,classes)]
        lsup = [residuals.min() + width*i for i in range(1,classes)] + [residuals.max()]

        # List of Frequencies by Interval
        frequence = [0]*classes

        # Counting Frequence in each Interval
        for value in residuals:
            for i in range(classes):
                if linf[i] <= value < lsup[i]:
                    frequence[i] += 1
                    break
        frequence[-1] += 1

        # Residuals Standard Deviation
        residuals_std = (model_data['anova_table']['median_square'][1])**(1/2)

        # Cumulative Distribution Function
        cdf = [stats.norm.cdf(lsup[0], scale=residuals_std, loc=0)] + [stats.norm.cdf(lsup[i], scale=residuals_std, loc=0) - stats.norm.cdf(linf[i], scale=residuals_std, loc=0) for i in range(1,classes-1)] + [1-stats.norm.cdf(lsup[classes-2], scale=residuals_std, loc=0)]

        # Expected Frequency
        exp_freq = [i*n for i in cdf]
        
        quotient = [np.square(exp_freq[i] - frequence[i])/exp_freq[i] for i in range(classes)]

        test_statistic = sum(quotient)

        # Chi Square Inverse Functions with alpha = 0.05 and n = classes - 2
        chi_square = stats.chi2.isf(.05, classes-2)

        if test_statistic > chi_square:
            normal_0_mean_hypothesis = f"{test_statistic.__round__(4)} > {chi_square.__round__(4)}, Residuals come from another distribution"
        else:
            normal_0_mean_hypothesis = f"{test_statistic.__round__(4)} < {chi_square.__round__(4)}, Residuals come from a Normal distribution with mean 0"
        
        # QQPLOT: Also for Normal Distribution Asumption
        qqplot = global_functions.qqplot(residuals,residuals_std**2)
        
        # INCORRELATION ASSUMPTION
        # H0: p = 0, which means the analysed data doesn't have correlation
        # Ha: p > 0, which means the analysed data has correlation
        # Reject H0 if d < dL
        # Don't rehect H0 if d > dU
        # Inconclusive test if dL < d < dU
        d = sum(np.square([residuals[i+1] - residuals[i] for i in range(n-1)]))/sum(np.square(residuals))
        
        finding_row = durbin_watson.loc[(durbin_watson['sample_size'] == len(df)) & (durbin_watson['n_terms'] == len(df.columns))].reset_index(drop=True)
        dL = finding_row['DL'][0]
        dU = finding_row['DU'][0]
        
        if d < dL:
            incorrelation_test = f"{d} < {dL}, Correlated data."
        elif d > dU:
            incorrelation_test = f"{d} > {dU}, Incorrelated data."
        else:
            incorrelation_test = f"{dL} < {d} < {dU}, Inconclusive test."
        
        # ATYPICAL DATA
        
        # Residuals Mean
        residuals_mean = np.mean(residuals)
        # Standarized Residuals
        standarized_residuals = [(value-residuals_mean)/(residuals_std) for value in residuals]
        # Finding Atypical Data
        atypical_data = {f'Observation {i+1} with Standarized Value {value}':residuals[i] for i,value in enumerate(standarized_residuals) if abs(value) > 3}
        # If there is not atypical data, it will tell the user
        if len(atypical_data) == 0:
            atypical_data = "There is not atypical data in the sample"
        
        return {'estimated_ec':estimated_ecuation, 'significance_test':significance_test, 'r_square':r_square, 'performance_level':performance_level, 'residuals_variance':residuals_variance, 'model_graph':model_graph, 'coef_intervals':coeficient_intervals, 'anova_table':anova_table, 'constant_variance_plot':constant_variance_plot, 'Normal_0_mean':normal_0_mean_hypothesis, 'qqplot':qqplot, 'incorrelation_test':incorrelation_test, 'atypical_data':atypical_data}

# This is the official class for the correlation data of the SIMPLE REGRESSION MODELS  
class webAppCorrSimple:
    # Correlation Plot. Plot to se how correlated the "X" and "Y" variables are (X is the independient and Y is the dependient variable)
    def correlation_plot(df):
        correlation_plot = global_functions.scatter_plot(df,'Correlation Plot')
        return correlation_plot
    
    # This function will tell you how correlated your data is
    def correlation(df):
        correl = df.corr().iloc[1,0]
        
        if abs(correl) == 1 and correl > 0:
            return f"Correlation: {correl}\nPerfect Positive Correlation"
        elif abs(correl) == 1 and correl < 0:
            return f"Correlation: {correl}\nPerfect Negative Correlation"
        elif abs(correl) > .9 and correl > 0:
            return f"Correlation: {correl}\nVery Strong Positive Correlation"
        elif abs(correl) > .9 and correl < 0:
            return f"Correlation: {correl}\nVery Strong Negative Correlation"
        elif abs(correl) > .7 and correl > 0:
            return f"Correlation: {correl}\nStrong Positive Correlation"
        elif abs(correl) > .7 and correl < 0:
            return f"Correlation: {correl}\nStrong Negative Correlation"
        elif abs(correl) > .4 and correl > 0:
            return f"Correlation: {correl}\nModerate Positive Correlation"
        elif abs(correl) > .4 and correl < 0:
            return f"Correlation: {correl}\nModerate Negative Correlation"
        elif abs(correl) > .2 and correl > 0:
            return f"Correlation: {correl}\nWeak Positive Correlation"
        elif abs(correl) > .2 and correl < 0:
            return f"Correlation: {correl}\nWeak Negative Correlation"
        elif correl > 0:
            return f"Correlation: {correl}\nNegligible Positive Correlation"
        else:
            return f"Correlation: {correl}\nNegligible Negative Correlation"

# Official class of the correlation data for the MULTIPLE REGRESSION MODELS
class webAppCorrMultiple:
    # Correlation heatmap. Plot made from the class "plots"
    def correlation_matrix_heatmap(df):
        plot = plots.correl_matrix_plot(df)
        return plot
    
    # Correlation Matrix Table.
    def correlation_matrix_table(df):
        table = df.corr()
        return table

# Class with calculations for the MULTIPLE REGRESSION MODELS
class RegMultiple:
    # This function returns a list with the following data: y forecast (numpy array), betas (Data Frame), ecuation (string), Cjj (list)
    def ecuation_est(X,Y,regressionToOrigin):
        
        if regressionToOrigin == False:
            X = sm.add_constant(X)

        betas = pd.DataFrame()
        betas["variable"] = X.columns

        X = X.values
        Y = Y.values
        Xt = X.T 
        XtX = np.dot(Xt,X)
        XtX_inv = np.linalg.inv(XtX)
        XtX_inv_Xt = np.dot(XtX_inv,Xt)
        b = np.dot(XtX_inv_Xt,Y)

        betas["beta"] = b
        
        y_est = np.dot(X,b)
        
        if regressionToOrigin == False:
            ecuation = f"Ŷ = {b[0][0].__round__(2)}"
        else:
            ecuation = f"Ŷ ="

        s = {
            0: '₀',
            1: '₁',
            2: '₂',
            3: '₃',
            4: '₄',
            5: '₅',
            6: '₆',
            7: '₇',
            8: '₈',
            9: '₉'
        }
        
        sDef = lambda x: s[x] if x<10 else s[int(str(x)[:1])] + s[int(str(x)[1:])]
        for i,beta in enumerate(b[1:]):
            if beta >= 0:
                ecuation += f" +{beta[0].__round__(2)}X{sDef(i+1)}"
            else:
                ecuation += f" -{-beta[0].__round__(2)}X{sDef(i+1)}"
                
        Cjj = [XtX_inv[i][i] for i in range(len(XtX_inv))]
        
        # For the Hat matrix
        # The formula is the diagonal of X(X'X)^(-1)X'
        H = np.dot(np.dot(X,XtX_inv),Xt)
        hi = H.diagonal()
        
        return y_est,betas,ecuation,Cjj,hi
    
    # This function depends on the "ecuation_est()" function. It returns a dict with the anova table (data frame), r_square (int. which means Variability of the Model for multiple regression), 
    # r_squared_adj (int. which measures the model performance), significance test (str), betas (numpy array), y forecast (numpy array), residuals (numpy array), and the estimated ecuation (str)
    def anova_table(df, y_index, y_name, regToOrigin):
        Y = df.iloc[:,y_index:y_index+1]
        X = df.drop(y_name, axis=1)

        ec_est = RegMultiple.ecuation_est(X,Y,regToOrigin)
        Y_est = ec_est[0]
        residuals = (np.array(Y) - Y_est).T[0]
        
        b = ec_est[1]
        ecuation = ec_est[2]

        n = len(df)
        k = len(X.columns)

        anova_table =pd.DataFrame()

        anova_table['source_of_variation'] = ['Regression','Residuals','Total']
        anova_table['degrees_of_freedom'] = pd.Series([k,n-k-1,n-1])
        
        SSR = sum(np.square(Y_est-Y_est.mean()))[0]
        SSE = sum(np.square(Y.values - Y_est))[0]
        SST = sum(np.square(Y.values - Y_est.mean()))[0]
        anova_table['sum_of_squares'] = pd.Series([SSR,SSE,SST])

        MSR = SSR/k
        MSE = SSE/(n-k-1)
        anova_table['half_square'] = pd.Series([MSR,MSE])
        f0 = MSR/MSE
        anova_table['f0'] = pd.Series([f0])

        f_alpha = stats.f.isf(.05,k,n-k-1)

        significance_test = linearization.significance_test(f0,f_alpha)
        
        r_square = SSR/SST
        
        r_square_adj = 1- (1-r_square) * (n-1)/(n-k-1)
        
        hi = ec_est[4]
        
        return {'anova_table':anova_table,'r_square':r_square,'r_square_adj':r_square_adj,'significance_test':significance_test, 'bi':b, 'y_est':Y_est.T[0],'residuals':residuals, 'est_ecuation':ecuation, 'hi':hi}
    
# Official class for the MULTIPLE REGRESSION MODELING outputs    
class webAppRegMultiple:
    # Will return assumption plots and results, contains also the model data calculated with the "anova_table" function from the "RegMultiple" class
    # TO DEFINE: THE DATA THAT WE WANT TO RETURN FROM THE model_data VARIABLE
    def mult_reg_model(df, regToOrigin):
        y_definition = global_functions.select_y_var(df)
        y_name = y_definition['y_name']
        y_index = y_definition['y_index']
        
        model_data = RegMultiple.anova_table(df,y_index,y_name, regToOrigin)
        
        ## ASSUMPTIONS
        versus_fits_df = pd.DataFrame({'Fitted Value':model_data['y_est'],'Residuals':model_data['residuals']})
        versus_order_df = pd.DataFrame({'Observation Order':[i for i in range(1,len(df) + 1)],'Residuals':model_data['residuals']})

        # RESIDUALS CONSTANT VARIANCE
        # Versus Fits Plot
        versus_fit_plt =global_functions.scatter_plot(versus_fits_df,'Versus Fits')

        # INCORRELATION OF THE RESIDUALS
        # Versus Order Plot
        versus_order_plt = global_functions.scatter_plot(versus_order_df,'Versus Order')
        
        # NORMALITY OF THE RESIDUALS
        # To visually analyze it we can use the qqplot
        normal_prob_plt = global_functions.qqplot(model_data['residuals'],model_data['anova_table']['half_square'][1])
        
        # Normality mean 0 variance of the residuals
        normal_0_mean_asumption, normal_0_mean_hist =global_functions.normality_0_mean(model_data['anova_table'],model_data['residuals'])
        
        # INCORRELATED RESIDUALS ASSUMPTION
        # For this test we're going to need the sample size "n" (the function calculates it), number of independient variables "k" and residuals
        incorrel_res_assumption = global_functions.incorrelation_assumption(model_data['residuals'],len(df.columns) - 1)
        
        # ATYPICAL DATA
        # The parameters to use the function are the residuals, the variance of the residuals, and the Hat values
        atypical_data = global_functions.atypical_data(model_data['residuals'],model_data['anova_table']['half_square'][1], model_data['hi'])
        
        return {'versus_fit':versus_fit_plt,'versus_order':versus_order_plt,'qqplot':normal_prob_plt,'normal_0_mean_assumption':normal_0_mean_asumption,'normal_0_mean_hist':normal_0_mean_hist,'incorrel_res_assumption':incorrel_res_assumption,'atypical_data':atypical_data,'model_data':model_data}
    
    # Returns a data frame with a summary for the coefficients (name of the terms, value of the coefficients, confidence interval for the coefficients and its VIF)
    # This table is essential at the begining, where you run the model with all the variables of the sample. If you have a VIF higher than 10, it is recommended to eliminate the variable with the higher VIF,
    # or to expand the sample size.
    def coef_summary(df, regToOrigin):
        # Function for selecting the "y" column in the dataframe
        y_definition = global_functions.select_y_var(df)
        y_name = y_definition['y_name']
        y_index = int(y_definition['y_index'])

        # Dataframe for "X" variables and "Y" variable columns
        X = df.drop(y_name, axis=1)
        
        if regToOrigin == False:
            X = sm.add_constant(X)
        Y = df.iloc[:,y_index:y_index+1]

        # VIF
        # VIF formula is VIFj = 1/(1-Rj^2)
        # Using the anova table function to determine Rj^2 which is the multiple determination coefficient obtained by doing the regression "Xi" on the other regresion variables.
        models_data = [RegMultiple.anova_table(X, index, name, regToOrigin) for index,name in enumerate(X.columns)]
        # Variability of the estimated regressions (r squared)
        r_square = [i['r_square'] for i in models_data]
        # VIF
        VIF = [1/(1-i) for i in r_square]
        
        #95% CONFIDENCE INTERVALS
        # Bj_estimated - t.inv(alpha/2,n-p)*(res_variance*Cjj) < Bj < Bj_estimated + t.inv(alpha/2,n-p)*(res_variance*Cjj)
        # Cjj is the element of the diagonal (X'X)^-1
        # p is the total number of parameters in the regression model
        
        # Annova table for the estimated ecuation
        anova_est_ec = RegMultiple.anova_table(df,y_index,y_name,regToOrigin)
        # Variance of the Residuals of the estimated ecuation
        residuals_var = anova_est_ec['anova_table']['half_square'][1]
        
        # Ec Estimation data
        ec_est_data = RegMultiple.ecuation_est(X,Y,regToOrigin)
        # Coefficients (b0,b1,..,bk)
        bi = ec_est_data[1]

        # Cjj (Inverse of (XtX)^-1)
        Cjj = ec_est_data[3]
        
        # Confidence Intervals for betas
        n = len(df)
        p = len(df.columns)
        t_alpha = stats.t.isf(.05/2,n-p)
        
        CI_LT = [beta-t_alpha*np.sqrt(Cjj[i]*residuals_var) for i,beta in enumerate(bi['beta'])]
        CI_RI = [beta+t_alpha*np.sqrt(Cjj[i]*residuals_var) for i,beta in enumerate(bi['beta'])]

        confidence_intervals = [f"{CI_LT[i].__round__(4)} < b{i} < {CI_RI[i].__round__(4)}" for i in range(len(CI_LT))]
        
        coefficients_summary = pd.DataFrame()
        coefficients_summary['Term'] = X.columns
        coefficients_summary['Coef'] = bi['beta']
        coefficients_summary['95% CI'] = confidence_intervals
        coefficients_summary['VIF'] = VIF
        
        return coefficients_summary
    
    # This function will return a dataframe with the top 2 models for all of the different sizes of the independient variables (top 2 for a model with 1 independient variable, 2, 3, ..., k)
    # It will show which variables make up each model, with its performance (r_squared_adj) and its variability (r_squared)
    def top_models(df, regToOrigin):
        # Function for selecting the "y" column in the dataframe
        y_definition = global_functions.select_y_var(df)
        y_name = y_definition['y_name']
        y_index = int(y_definition['y_index'])

        # Dataframe for "X" variables and "Y" variable columns
        X = df.drop(y_name, axis=1)
        Y = df.iloc[:,y_index:y_index+1]
        
        variables = X.columns
        all_combinations = []
        r_square = []
        r_square_adj = []
        S = []

        df_x = []
        for i in range(1,len(X.columns)+1):
            comb = combinations(X.columns,i)
            for c in comb:
                all_combinations.append(c)
                df_x.append(df.loc[:,c])
        df_for_regression = [pd.concat([Y, X_vars], axis=1) for X_vars in df_x]
        model = [RegMultiple.anova_table(df,y_index,y_name,regToOrigin) for df in df_for_regression]
        [r_square.append(m['r_square']) for m in model]
        [r_square_adj.append(m['r_square_adj']) for m in model]
        [S.append(m['anova_table']['half_square'][1]) for m in model]
        
        rows = []      
        for comb in all_combinations:
            row = ['X' if var in comb else '' for var in variables]
            row.insert(0,len(comb))
            rows.append(row)

        results_df = pd.DataFrame(rows,columns=['Vars'] + X.columns.tolist())
        results_df['R sq'] = np.round(np.array(r_square)*100,4)
        results_df['R sq (adj)'] = np.round(np.array(r_square_adj)*100,4)
        results_df['S'] = np.round(np.array(S)**.5,4)

        # Ordenar el DataFrame por 'num_vars' y luego por 'R sq'
        df_sorted = results_df.sort_values(by=['Vars', 'R sq (adj)'], ascending=[True, False])

        # Seleccionar el top 2 de cada grupo de 'num_vars'
        top_n_per_group = df_sorted.groupby('Vars').head(2).reset_index(drop=True)
        
        return top_n_per_group